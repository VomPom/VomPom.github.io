{"data":{"title":"Android音视频-初识FFmpeg","slug":"音视频-初识FFmpeg","description":"","date":"2021-11-14T01:49:00.000Z","updated":"2025-09-15T13:07:56.100Z","language":"zh-CN","comments":true,"url":"2021/11/14/音视频-初识FFmpeg/","cover":null,"images":[],"content":"<p>已经很久没有写过技术博客了，这段时间加入了新公司，主要时间花在熟悉新业务的技术上。而新的业务主要跟音视频相关，关于音视频的尝试在加入新公司之前，自己有做相关demo的尝试与学习，可以参看<a href=\"https://github.com/VomPom/JProject/tree/master/app/src/main/java/wang/julis/jproject/example/media\">音视频相关学习demo</a>。当然，那都是自己“想当然”学习的一些东西，虽然实际工作中并没有派上太大的用处，但让我对音视频相关的基础知识有了一定的概念，对后面的技术尝试做了铺垫。第一个技术挑战比较大的就是进行：<strong>视频抽帧</strong>，关于视频抽帧网上有很多很多文章进行讲解，但……我始终没有找到一个效率很高的解决方案。直到我遇见了 ffmpeg，仿佛打开了新世界的大门……</p>\n<h2 id=\"关于FFmpeg\"><a href=\"#关于FFmpeg\" class=\"headerlink\" title=\"关于FFmpeg\"></a>关于FFmpeg</h2><p>刚接触 ffmpeg 时，我一脸懵逼，完全不知道该怎么做，也不知道在哪里开始进行学习，后来在<a href=\"https://blog.csdn.net/leixiaohua1020\">雷霄骅大神的博客</a>中渐渐找到了感觉，膜拜！不过雷神的博客代码是基于老版本的 ffmpeg api，推荐搭配<a href=\"https://github.com/FFmpeg/FFmpeg/tree/master/doc/examples\">官方example</a>，先跑通雷声的博客，再对照官方的例子对进行api相关接口的修改。</p>\n<p>当然，想要使用 ffmpeg编写代码之前，我们首先要做的是对 FFmpeg 进行so库编译，这一步也是难倒了众多的英雄好汉，引用<a href=\"https://juejin.cn/post/6844904039524597773\">FFmpeg so库编译</a>作者的话：</p>\n<blockquote>\n<p>为什么FFmpeg让人觉得很难搞？<br>我想主要是因为迈出第一步就很困难，连so库都编译不出来，后面的都是扯淡了。</p>\n</blockquote>\n<p>参考<a href=\"https://juejin.cn/post/6844904039524597773\">FFmpeg so库编译</a>文章能成功地打包出 ffmpeg.so，接下来就是添加在项目中运行。</p>\n<h2 id=\"踏上-FFmpeg-音视频之路\"><a href=\"#踏上-FFmpeg-音视频之路\" class=\"headerlink\" title=\"踏上 FFmpeg 音视频之路\"></a>踏上 FFmpeg 音视频之路</h2><p>关于音视频等开发，无论是做特效渲染还是做视频播放，那么最重要也是最基本的步骤就是：<strong>音视频解码</strong></p>\n<p>众所周知的是视频是由一帧帧视频帧(图片)&#x2F;音频帧编码组合而成</p>\n<p>视频解码要做的就是解码出视频文件中的每一帧，我们以:<strong>将视频转化为一帧帧的图片</strong>作为例进行学习。</p>\n<h2 id=\"FFmpeg-提取视频每一帧图像\"><a href=\"#FFmpeg-提取视频每一帧图像\" class=\"headerlink\" title=\"FFmpeg 提取视频每一帧图像\"></a>FFmpeg 提取视频每一帧图像</h2><p>在学习之前，我们思考一个问题：抛开 ffmpeg，如果让你去设计一个提取的代码，n你会怎么设计？</p>\n<p>因为视频是以文件流的形式存在，我相信很多人一上来就能想到这样的结构：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span> (!EOF) &#123; <span class=\"comment\">//当文件流没有结束</span></span><br><span class=\"line\">    <span class=\"type\">Stream</span> <span class=\"variable\">stream</span> <span class=\"operator\">=</span> getStream(); <span class=\"comment\">//获取一定区域的stream</span></span><br><span class=\"line\">    <span class=\"type\">Frame</span> <span class=\"variable\">steam</span> <span class=\"operator\">=</span> getFrame(stream); <span class=\"comment\">//Stream转化为视频帧</span></span><br><span class=\"line\">    <span class=\"type\">Picture</span> <span class=\"variable\">picture</span> <span class=\"operator\">=</span> decodeFrame(steam); <span class=\"comment\">//将视频帧转化为 .jpeg等格式图片</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>的确是这样的，这里是给出一份ffmpeg提取视频帧图片的核心逻辑：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\">AVFrame frame = av_frame_alloc(); </span><br><span class=\"line\"><span class=\"keyword\">while</span> (<span class=\"literal\">true</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (av_read_frame(fmt_ctx, &amp;avpkt) &gt;= <span class=\"number\">0</span>) &#123; <span class=\"comment\">// Return the next frame of a stream.</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (avpkt.stream_index == video_stream_index) &#123; <span class=\"comment\">//标识该AVPacket所属的视频/音频流。</span></span><br><span class=\"line\">            avcodec_send_packet(codeCtx, &amp;avpkt); <span class=\"comment\">//Supply raw packet data as input to a decoder.</span></span><br><span class=\"line\">            <span class=\"keyword\">while</span> (avcodec_receive_frame(codeCtx, frame) == <span class=\"number\">0</span>) &#123; <span class=\"comment\">//Return decoded output data from a decoder.</span></span><br><span class=\"line\">                <span class=\"built_in\">snprintf</span>(buf, <span class=\"keyword\">sizeof</span>(buf), <span class=\"string\">&quot;%s/frame-%d.jpg&quot;</span>, out_filename, frame_count);</span><br><span class=\"line\">                saveJpg(frame, buf);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            frame_count++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        av_packet_unref(&amp;avpkt);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        LOGE(<span class=\"string\">&quot;//Exit&quot;</span>);</span><br><span class=\"line\">        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>上面的代码块就是 ffmpeg 进行视频解码最核心的逻辑了，主要的注释也贴在了代码上，完整代码请查看<a href=\"https://github.com/VomPom/FFmpegLearn/blob/main/app/src/main/cpp/func/video_to_jpeg.cpp\">video_to_jpeg.cpp</a>，查看完整的代码后，会感觉到很惊讶：为什么这么复杂？特别是前面的初始化操作。放心，ffmpeg就像一套组合拳，有固定不变的套路，写一次就足够了，了解了其中的流程，之后理解起来就会很容易了。</p>\n<p>上面的代码我们还可以做一些其他处理，比如只获取关键帧、查找指定时间戳位置的帧、视频按2s一帧进行抽取、视频不保存为jpeg文件转化为Java的bitmap？</p>\n<p>这些实现需求也都是基于上述核心模块进行修改：</p>\n<p>如果<strong>想只获取关键帧</strong>，可以利用<code>AVFrame</code>对象的属性<code>AVFrame-&gt;key_frame</code>进行判断。</p>\n<p><strong>查找指定时间戳位置的帧</strong>：利用 <code>av_seek_frame</code>查找到指定帧时间最近的关键帧，然后依次进行编码，直到<code>pts</code>与目标时间相近</p>\n<p><strong>视频按2s一帧进行抽取</strong>：简单的操作可以去获取视频fps，比如视频25fps，可以使用一个计数器判断<code>if(frame_count%25==0)</code>,这时候则是刚好1s。当然这样子性能不太好。如果需要追求性能，那么也可以利用<code>av_seek_frame</code>，查找目标时间附近，然后循环进行解码直到目标时间。</p>\n<p><strong>视频不保存为jpeg文件转化为Java的Bitmap</strong>：只需要对最终获取的 <code>AVFrame</code>做不一样的操作进行了，获取到对应的buffer，再利用jni调用构造 Java 的 bitmap 对象。</p>\n<p>可以做的还有很多……</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>提取视频图片这个功能只是 FFmpeg 强大功能的九牛一毛，需要探究的还有很多很多……</p>\n<p>如果能跑起来 FFmpeg 最简单的例子，已经迈出了很大一步了，但如果要理解其中的原理，还需要更多的基础知识，以及像<code>AVPacket</code>、<code>AVFrame</code>、 <code>AVCodec</code> ……每一个类的数据结构，以及实现都需要仔细研究。</p>\n<p>自己在网上找到的 FFmpeg 相关的教程，以及自己想要去实现的功能的资源太少，很多东西都需要自己去摸索。有时候我总在怀疑：<strong>为什么这么基础且很实用的功能没有现成的轮子？</strong> 这可能也是现在音视频相关开发的现状吧，成熟可用的轮子相对而言较少，以及相关技术的分享可能不太好做。既然没有，那就靠自己一点点积累吧。</p>\n<p>学习之路，任重而道远呐。</p>\n","raw":"title: Android音视频-初识FFmpeg\nauthor: 落叶挽歌\ntags:\n  - FFmpeg\n  - 音视频\ncategories:\n  - 技术文章\ndate: 2021-11-14 09:49:00\n---\n\n已经很久没有写过技术博客了，这段时间加入了新公司，主要时间花在熟悉新业务的技术上。而新的业务主要跟音视频相关，关于音视频的尝试在加入新公司之前，自己有做相关demo的尝试与学习，可以参看[音视频相关学习demo](https://github.com/VomPom/JProject/tree/master/app/src/main/java/wang/julis/jproject/example/media)。当然，那都是自己“想当然”学习的一些东西，虽然实际工作中并没有派上太大的用处，但让我对音视频相关的基础知识有了一定的概念，对后面的技术尝试做了铺垫。第一个技术挑战比较大的就是进行：**视频抽帧**，关于视频抽帧网上有很多很多文章进行讲解，但……我始终没有找到一个效率很高的解决方案。直到我遇见了 ffmpeg，仿佛打开了新世界的大门……\n\n## 关于FFmpeg\n\n刚接触 ffmpeg 时，我一脸懵逼，完全不知道该怎么做，也不知道在哪里开始进行学习，后来在[雷霄骅大神的博客](https://blog.csdn.net/leixiaohua1020)中渐渐找到了感觉，膜拜！不过雷神的博客代码是基于老版本的 ffmpeg api，推荐搭配[官方example](https://github.com/FFmpeg/FFmpeg/tree/master/doc/examples)，先跑通雷声的博客，再对照官方的例子对进行api相关接口的修改。\n\n当然，想要使用 ffmpeg编写代码之前，我们首先要做的是对 FFmpeg 进行so库编译，这一步也是难倒了众多的英雄好汉，引用[FFmpeg so库编译](https://juejin.cn/post/6844904039524597773)作者的话：\n\n>为什么FFmpeg让人觉得很难搞？\n>我想主要是因为迈出第一步就很困难，连so库都编译不出来，后面的都是扯淡了。\n\n参考[FFmpeg so库编译](https://juejin.cn/post/6844904039524597773)文章能成功地打包出 ffmpeg.so，接下来就是添加在项目中运行。\n\n## 踏上 FFmpeg 音视频之路\n\n关于音视频等开发，无论是做特效渲染还是做视频播放，那么最重要也是最基本的步骤就是：**音视频解码**\n\n众所周知的是视频是由一帧帧视频帧(图片)/音频帧编码组合而成\n\n\n视频解码要做的就是解码出视频文件中的每一帧，我们以:**将视频转化为一帧帧的图片**作为例进行学习。\n\n## FFmpeg 提取视频每一帧图像\n\n在学习之前，我们思考一个问题：抛开 ffmpeg，如果让你去设计一个提取的代码，n你会怎么设计？\n\n因为视频是以文件流的形式存在，我相信很多人一上来就能想到这样的结构：\n\n```java\nwhile (!EOF) { //当文件流没有结束\n    Stream stream = getStream(); //获取一定区域的stream\n    Frame steam = getFrame(stream); //Stream转化为视频帧\n    Picture picture = decodeFrame(steam); //将视频帧转化为 .jpeg等格式图片\n}\n```\n\n的确是这样的，这里是给出一份ffmpeg提取视频帧图片的核心逻辑：\n\n```c\n    AVFrame frame = av_frame_alloc(); \n    while (true) {\n        if (av_read_frame(fmt_ctx, &avpkt) >= 0) { // Return the next frame of a stream.\n            if (avpkt.stream_index == video_stream_index) { //标识该AVPacket所属的视频/音频流。\n                avcodec_send_packet(codeCtx, &avpkt); //Supply raw packet data as input to a decoder.\n                while (avcodec_receive_frame(codeCtx, frame) == 0) { //Return decoded output data from a decoder.\n                    snprintf(buf, sizeof(buf), \"%s/frame-%d.jpg\", out_filename, frame_count);\n                    saveJpg(frame, buf);\n                }\n                frame_count++;\n            }\n            av_packet_unref(&avpkt);\n        } else {\n            LOGE(\"//Exit\");\n            break;\n        }\n    }\n```\n\n上面的代码块就是 ffmpeg 进行视频解码最核心的逻辑了，主要的注释也贴在了代码上，完整代码请查看[video_to_jpeg.cpp](https://github.com/VomPom/FFmpegLearn/blob/main/app/src/main/cpp/func/video_to_jpeg.cpp)，查看完整的代码后，会感觉到很惊讶：为什么这么复杂？特别是前面的初始化操作。放心，ffmpeg就像一套组合拳，有固定不变的套路，写一次就足够了，了解了其中的流程，之后理解起来就会很容易了。\n\n上面的代码我们还可以做一些其他处理，比如只获取关键帧、查找指定时间戳位置的帧、视频按2s一帧进行抽取、视频不保存为jpeg文件转化为Java的bitmap？\n\n这些实现需求也都是基于上述核心模块进行修改：\n\n如果**想只获取关键帧**，可以利用`AVFrame`对象的属性`AVFrame->key_frame`进行判断。\n\n**查找指定时间戳位置的帧**：利用 `av_seek_frame`查找到指定帧时间最近的关键帧，然后依次进行编码，直到`pts`与目标时间相近\n\n**视频按2s一帧进行抽取**：简单的操作可以去获取视频fps，比如视频25fps，可以使用一个计数器判断`if(frame_count%25==0)`,这时候则是刚好1s。当然这样子性能不太好。如果需要追求性能，那么也可以利用`av_seek_frame`，查找目标时间附近，然后循环进行解码直到目标时间。\n\n**视频不保存为jpeg文件转化为Java的Bitmap**：只需要对最终获取的 `AVFrame`做不一样的操作进行了，获取到对应的buffer，再利用jni调用构造 Java 的 bitmap 对象。\n\n可以做的还有很多……\n\n## 总结\n\n提取视频图片这个功能只是 FFmpeg 强大功能的九牛一毛，需要探究的还有很多很多……\n\n如果能跑起来 FFmpeg 最简单的例子，已经迈出了很大一步了，但如果要理解其中的原理，还需要更多的基础知识，以及像`AVPacket`、`AVFrame`、 `AVCodec` ……每一个类的数据结构，以及实现都需要仔细研究。\n\n自己在网上找到的 FFmpeg 相关的教程，以及自己想要去实现的功能的资源太少，很多东西都需要自己去摸索。有时候我总在怀疑：**为什么这么基础且很实用的功能没有现成的轮子？** 这可能也是现在音视频相关开发的现状吧，成熟可用的轮子相对而言较少，以及相关技术的分享可能不太好做。既然没有，那就靠自己一点点积累吧。\n\n学习之路，任重而道远呐。\n","categories":[{"name":"技术文章","api":"api/categories/technology.json"}],"tags":[{"name":"FFmpeg","api":"api/tags/FFmpeg.json"},{"name":"音视频","api":"api/tags/音视频.json"}]},"api":"api/posts/2021/11/14/音视频-初识FFmpeg.json"}