{"data":{"index":1,"total":1,"posts":[{"title":"实现一个自定义 FFmpeg Filter","slug":"实现一个自定义FFmpeg-Filter","date":"2024-03-07T02:58:00.000Z","updated":"2025-05-20T11:46:57.000Z","comments":true,"url":"2024/03/07/实现一个自定义FFmpeg-Filter/","excerpt":"<p>此前在做  ffmpeg+某个第三库作为 filter 的集成，第三库是做AE特效相关的，与 ffmpeg 结合能让视频渲染效果大大提升。整体流程将第三方库作为 ffmpeg 的一个filter 形式进行结合，其中就涉及到 ffmpeg 的 filter 开发，本文即 对ffmpeg 的滤镜开发流程作一个总结。本文以实现一个视频垂直翻转的 filter 为例，ffmpeg 源码基于<a href=\"https://github.com/FFmpeg/FFmpeg/tree/release/6.1\">FFmpeg6.1</a> </p>\n<h2 id=\"实现自定义-Filter-流程\"><a href=\"#实现自定义-Filter-流程\" class=\"headerlink\" title=\"实现自定义 Filter 流程\"></a>实现自定义 Filter 流程</h2><ul>\n<li><p>编写 filter.c 文件</p>\n<p>一般视频滤镜以 vf_ 为前缀，视频滤镜以 af_ 为前缀，放在libavfilter目录下，参考其他 filter 代码逻辑，模块化配置相关参数，本文例以 vf_flip.c 实现视频的上下翻转</p>\n</li>\n<li><p>在 <code>libavfilter/allfilters.c</code> 注册</p>\n<p>例如：extern const AVFilter ff_vf_flip;  <code>ff_vf_flip</code>就是在 <code>vf_flip.c</code>的 filter 注册名称</p>\n</li>\n<li><p>修改 <code>libavfilter/Makefile</code> 添加编译配置： </p>\n<p>例如：OBJS-$(CONFIG_FLIP_FILTER)                   +&#x3D; vf_flip.o</p>\n</li>\n<li><p>编译打包</p>\n</li>\n</ul>\n<h2 id=\"编写-filter-c-文件\"><a href=\"#编写-filter-c-文件\" class=\"headerlink\" title=\"编写 filter.c 文件\"></a>编写 filter.c 文件</h2><h3 id=\"AVFilter主体\"><a href=\"#AVFilter主体\" class=\"headerlink\" title=\"AVFilter主体\"></a>AVFilter主体</h3><figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">AVFilter</span> &#123;</span></span><br><span class=\"line\">  <span class=\"type\">const</span> <span class=\"type\">char</span> *name;</span><br><span class=\"line\">  <span class=\"type\">const</span> <span class=\"type\">char</span> *description;</span><br><span class=\"line\">  <span class=\"type\">const</span> AVFilterPad *inputs;</span><br><span class=\"line\">  <span class=\"type\">const</span> AVFilterPad *outputs;</span><br><span class=\"line\">  <span class=\"type\">const</span> AVClass *priv_class;</span><br><span class=\"line\">  <span class=\"type\">int</span> flags;</span><br><span class=\"line\">  <span class=\"type\">int</span> (*preinit)(AVFilterContext *ctx);</span><br><span class=\"line\">  <span class=\"type\">int</span> (*init)(AVFilterContext *ctx);</span><br><span class=\"line\">  <span class=\"type\">int</span> (*init_dict)(AVFilterContext *ctx, AVDictionary **options);</span><br><span class=\"line\">  <span class=\"type\">void</span> (*uninit)(AVFilterContext *ctx);</span><br><span class=\"line\">  <span class=\"type\">int</span> (*query_formats)(AVFilterContext *);</span><br><span class=\"line\">  <span class=\"type\">int</span> priv_size;   </span><br><span class=\"line\">  <span class=\"type\">int</span> flags_internal; </span><br><span class=\"line\">  <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">AVFilter</span> *<span class=\"title\">next</span>;</span></span><br><span class=\"line\">  <span class=\"type\">int</span> (*process_command)(AVFilterContext *, <span class=\"type\">const</span> <span class=\"type\">char</span> *cmd, <span class=\"type\">const</span> <span class=\"type\">char</span> *arg, <span class=\"type\">char</span> *res, <span class=\"type\">int</span> res_len, <span class=\"type\">int</span> flags);</span><br><span class=\"line\">  <span class=\"type\">int</span> (*init_opaque)(AVFilterContext *ctx, <span class=\"type\">void</span> *opaque);</span><br><span class=\"line\">  <span class=\"type\">int</span> (*activate)(AVFilterContext *ctx);</span><br><span class=\"line\">&#125; AVFilter;</span><br></pre></td></tr></table></figure>\n\n<p>具体里面的属性作用可以参考：<a href=\"https://www.cnblogs.com/TaigaCon/p/10171464.html\">[ffmpeg] 定制滤波器</a>，可以根据需求实现里面的相关函数，接下来以一个最简单的 Filter 和一个较复杂一点的 Filter 举例。</p>\n<h3 id=\"最简单的-AVFilter\"><a href=\"#最简单的-AVFilter\" class=\"headerlink\" title=\"最简单的 AVFilter\"></a>最简单的 AVFilter</h3><figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> &#123;</span></span><br><span class=\"line\">    <span class=\"type\">const</span> AVClass *<span class=\"class\"><span class=\"keyword\">class</span>;</span></span><br><span class=\"line\">&#125; NoopContext;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">int</span> <span class=\"title function_\">filter_frame</span><span class=\"params\">(AVFilterLink *link, AVFrame *frame)</span> &#123;</span><br><span class=\"line\">    av_log(<span class=\"literal\">NULL</span>, AV_LOG_INFO, <span class=\"string\">&quot;filter frame pts:%lld\\n&quot;</span>, frame-&gt;pts);</span><br><span class=\"line\">    NoopContext *noopContext = link-&gt;dst-&gt;priv;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ff_filter_frame(link-&gt;dst-&gt;outputs[<span class=\"number\">0</span>], frame);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">const</span> AVFilterPad noop_inputs[] = &#123;</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">                .name         = <span class=\"string\">&quot;default&quot;</span>,</span><br><span class=\"line\">                .type         = AVMEDIA_TYPE_VIDEO,</span><br><span class=\"line\">                .filter_frame = filter_frame,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">const</span> AVFilterPad noop_outputs[] = &#123;</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">                .name = <span class=\"string\">&quot;default&quot;</span>,</span><br><span class=\"line\">                .type = AVMEDIA_TYPE_VIDEO,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"type\">const</span> AVFilter ff_vf_noop = &#123;</span><br><span class=\"line\">        .name          = <span class=\"string\">&quot;noop&quot;</span>,</span><br><span class=\"line\">        .description   = NULL_IF_CONFIG_SMALL(<span class=\"string\">&quot;Pass the input video unchanged.&quot;</span>),</span><br><span class=\"line\">        .priv_size     = <span class=\"keyword\">sizeof</span>(NoopContext),</span><br><span class=\"line\">        FILTER_INPUTS(noop_inputs),</span><br><span class=\"line\">        FILTER_OUTPUTS(noop_outputs),</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>命令行运行：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ffmpeg -i test.mp4 -vf &quot;noop&quot; noop.mp4</span><br></pre></td></tr></table></figure>\n\n<p> 正常输出文件（对原片没有做任何更改）,这个 filter 的作用是将输入的视频帧不做任何处理地传递给下一个过滤器，在处理每帧的时候会打印处理的 PTS，麻雀虽小五脏俱全，它包含了一个 AVFilter 基础的结构：</p>\n<ol>\n<li><p><strong><code>NoopContext</code></strong></p>\n<p>这是一个简单的结构体，包含一个指向 AVClass 的指针。在这个例子中，实际上没有使用到 NoopContext 结构体的任何成员，因为这个过滤器没有需要存储的私有数据。</p>\n</li>\n<li><p><strong><code>filter_frame</code></strong> </p>\n<p>这个函数的作用是处理输入的视频帧。在这个例子中，它只是打印帧的 PTS（Presentation Time Stamp，显示时间戳）并将帧传递给下一个过滤器，不对帧做任何修改。</p>\n</li>\n<li><p><strong><code>noop_inputs</code> 和 <code>noop_outputs</code></strong></p>\n<p>这两个数组定义了过滤器的输入和输出 Pad。在这个例子中，输入 Pad 类型为 AVMEDIA_TYPE_VIDEO，并关联了 <code>filter_frame</code> 函数。输出 Pad 也是 AVMEDIA_TYPE_VIDEO 类型，但没有关联任何函数，因为输出直接由 <code>filter_frame</code> 函数处理。</p>\n</li>\n<li><p><strong><code>ff_vf_noop</code></strong></p>\n<p>这是一个 AVFilter 结构体实例，包含了过滤器的名称、描述、私有数据大小以及输入和输出 Pad。在这个例子中，过滤器的名称为 “noop”，描述为 “Pass the input video unchanged.”，这也就是在执行：<code>ffmpeg -filters</code> 看到的 Filter描述内容。</p>\n</li>\n</ol>\n<p>接下来看一个稍微复杂的一个 AVFilter，实现一个视频的上下翻转</p>\n<h3 id=\"复杂一点的-AVFilter\"><a href=\"#复杂一点的-AVFilter\" class=\"headerlink\" title=\"复杂一点的 AVFilter\"></a>复杂一点的 AVFilter</h3><figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">FlipContext</span> &#123;</span></span><br><span class=\"line\">    <span class=\"type\">const</span> AVClass *<span class=\"class\"><span class=\"keyword\">class</span>;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> duration;</span><br><span class=\"line\">&#125; FlipContext;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> OFFSET(x) offsetof(FlipContext, x)</span></span><br><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">const</span> AVOption flip_options[] = &#123;</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;duration&quot;</span>, <span class=\"string\">&quot;set flip duration&quot;</span>, OFFSET(duration), AV_OPT_TYPE_INT, &#123;.i64 = <span class=\"number\">0</span>&#125;, <span class=\"number\">0</span>, INT_MAX, .flags = AV_OPT_FLAG_FILTERING_PARAM&#125;,</span><br><span class=\"line\">        &#123;<span class=\"literal\">NULL</span>&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">static</span> av_cold <span class=\"type\">int</span> <span class=\"title function_\">flip_init</span><span class=\"params\">(AVFilterContext *ctx)</span> &#123;</span><br><span class=\"line\">    FlipContext *context = ctx-&gt;priv;</span><br><span class=\"line\">    av_log(<span class=\"literal\">NULL</span>, AV_LOG_ERROR, <span class=\"string\">&quot;Input duration: %d.\\n&quot;</span>, context-&gt;duration);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">static</span> av_cold <span class=\"type\">void</span> <span class=\"title function_\">flip_uninit</span><span class=\"params\">(AVFilterContext *ctx)</span> &#123;</span><br><span class=\"line\">    FlipContext *context = ctx-&gt;priv;</span><br><span class=\"line\">    <span class=\"comment\">// no-op 本例无需释放滤镜实例分配的内存、关闭文件、资源等</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 对输入的 AVFrame 进行翻转</span></span><br><span class=\"line\"><span class=\"type\">static</span> AVFrame *<span class=\"title function_\">flip_frame</span><span class=\"params\">(AVFilterContext *ctx, AVFrame *in_frame)</span> &#123;</span><br><span class=\"line\"> \t\tAVFilterLink *inlink = ctx-&gt;inputs[<span class=\"number\">0</span>];</span><br><span class=\"line\">    FlipContext *s = ctx-&gt;priv;</span><br><span class=\"line\">    <span class=\"type\">int64_t</span> pts = in_frame-&gt;pts;</span><br><span class=\"line\">    <span class=\"comment\">// 将时间戳（pts）转化以秒为单位的时间戳</span></span><br><span class=\"line\">    <span class=\"type\">float</span> time_s = TS2T(pts, inlink-&gt;time_base);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (time_s &gt; s-&gt;duration) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 超过对应的时间则直接输出in_frame</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> in_frame;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 创建输出帧并分配内存</span></span><br><span class=\"line\">    AVFrame *out_frame = av_frame_alloc();</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!out_frame) &#123;</span><br><span class=\"line\">        av_frame_free(&amp;in_frame);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out_frame;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 设置输出帧的属性</span></span><br><span class=\"line\">    out_frame-&gt;format = in_frame-&gt;format;</span><br><span class=\"line\">    out_frame-&gt;width = in_frame-&gt;width;</span><br><span class=\"line\">    out_frame-&gt;height = in_frame-&gt;height;</span><br><span class=\"line\">    out_frame-&gt;pts = in_frame-&gt;pts;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 分配输出帧的数据缓冲区</span></span><br><span class=\"line\">    <span class=\"type\">int</span> ret = av_frame_get_buffer(out_frame, <span class=\"number\">32</span>);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (ret &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        av_frame_free(&amp;in_frame);</span><br><span class=\"line\">        av_frame_free(&amp;out_frame);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out_frame;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 这个示例仅适用于 YUV 格式的视频。对于其他格式（如 RGB）</span></span><br><span class=\"line\">    <span class=\"comment\">// 翻转输入帧的数据到输出帧</span></span><br><span class=\"line\">    <span class=\"comment\">// 翻转了 Y 分量，然后翻转了 U 和 V 分量</span></span><br><span class=\"line\">    <span class=\"comment\">//</span></span><br><span class=\"line\">    <span class=\"type\">uint8_t</span> *src_y = in_frame-&gt;data[<span class=\"number\">0</span>];</span><br><span class=\"line\">    <span class=\"type\">uint8_t</span> *src_u = in_frame-&gt;data[<span class=\"number\">1</span>];</span><br><span class=\"line\">    <span class=\"type\">uint8_t</span> *src_v = in_frame-&gt;data[<span class=\"number\">2</span>];</span><br><span class=\"line\">    <span class=\"type\">uint8_t</span> *dst_y = out_frame-&gt;data[<span class=\"number\">0</span>] + (in_frame-&gt;height - <span class=\"number\">1</span>) * out_frame-&gt;linesize[<span class=\"number\">0</span>];</span><br><span class=\"line\">    <span class=\"type\">uint8_t</span> *dst_u = out_frame-&gt;data[<span class=\"number\">1</span>] + (in_frame-&gt;height / <span class=\"number\">2</span> - <span class=\"number\">1</span>) * out_frame-&gt;linesize[<span class=\"number\">1</span>];</span><br><span class=\"line\">    <span class=\"type\">uint8_t</span> *dst_v = out_frame-&gt;data[<span class=\"number\">2</span>] + (in_frame-&gt;height / <span class=\"number\">2</span> - <span class=\"number\">1</span>) * out_frame-&gt;linesize[<span class=\"number\">2</span>];</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; in_frame-&gt;height; i++) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">memcpy</span>(dst_y, src_y, in_frame-&gt;width);</span><br><span class=\"line\">        src_y += in_frame-&gt;linesize[<span class=\"number\">0</span>];</span><br><span class=\"line\">        dst_y -= out_frame-&gt;linesize[<span class=\"number\">0</span>];</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (i &lt; in_frame-&gt;height / <span class=\"number\">2</span>) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">memcpy</span>(dst_u, src_u, in_frame-&gt;width / <span class=\"number\">2</span>);</span><br><span class=\"line\">            <span class=\"built_in\">memcpy</span>(dst_v, src_v, in_frame-&gt;width / <span class=\"number\">2</span>);</span><br><span class=\"line\">            src_u += in_frame-&gt;linesize[<span class=\"number\">1</span>];</span><br><span class=\"line\">            src_v += in_frame-&gt;linesize[<span class=\"number\">2</span>];</span><br><span class=\"line\">            dst_u -= out_frame-&gt;linesize[<span class=\"number\">1</span>];</span><br><span class=\"line\">            dst_v -= out_frame-&gt;linesize[<span class=\"number\">2</span>];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> out_frame;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">int</span> <span class=\"title function_\">activate</span><span class=\"params\">(AVFilterContext *ctx)</span> &#123;</span><br><span class=\"line\">    AVFilterLink *inlink = ctx-&gt;inputs[<span class=\"number\">0</span>];</span><br><span class=\"line\">    AVFilterLink *outlink = ctx-&gt;outputs[<span class=\"number\">0</span>];</span><br><span class=\"line\">    AVFrame *in_frame = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    AVFrame *out_frame = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> ret = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"comment\">// 获取输入帧</span></span><br><span class=\"line\">    ret = ff_inlink_consume_frame(inlink, &amp;in_frame);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (ret &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ret;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 如果有输入帧，进行翻转处理</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (in_frame) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 对输出帧进行上下翻转处理</span></span><br><span class=\"line\">        out_frame = flip_frame(ctx, in_frame);</span><br><span class=\"line\">        <span class=\"comment\">// 将处理后的帧放入输出缓冲区</span></span><br><span class=\"line\">        ret = ff_filter_frame(outlink, out_frame);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (ret &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            av_frame_free(&amp;out_frame);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ret;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 如果没有输入帧，尝试请求一个新的输入帧</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!in_frame) &#123;</span><br><span class=\"line\">        ff_inlink_request_frame(inlink);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> status;</span><br><span class=\"line\">    <span class=\"type\">int64_t</span> pts;</span><br><span class=\"line\">    ret = ff_inlink_acknowledge_status(inlink, &amp;status, &amp;pts);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (ret &lt; <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ret;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (status == AVERROR_EOF) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 输入链接已经结束，设置输出链接的状态为 EOF</span></span><br><span class=\"line\">        ff_outlink_set_status(outlink, AVERROR_EOF, pts);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">AVFILTER_DEFINE_CLASS(flip);</span><br><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">const</span> AVFilterPad flip_inputs[] = &#123;</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">                .name = <span class=\"string\">&quot;default&quot;</span>,</span><br><span class=\"line\">                .type = AVMEDIA_TYPE_VIDEO,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">const</span> AVFilterPad flip_outputs[] = &#123;</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">                .name = <span class=\"string\">&quot;default&quot;</span>,</span><br><span class=\"line\">                .type = AVMEDIA_TYPE_VIDEO,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"type\">const</span> AVFilter ff_vf_flip = &#123;</span><br><span class=\"line\">        .name = <span class=\"string\">&quot;flip&quot;</span>,</span><br><span class=\"line\">        .description = NULL_IF_CONFIG_SMALL(<span class=\"string\">&quot;Flip the input video.&quot;</span>),</span><br><span class=\"line\">        .priv_size = <span class=\"keyword\">sizeof</span>(FlipContext),</span><br><span class=\"line\">        .priv_class = &amp;flip_class,</span><br><span class=\"line\">        .activate      = activate,</span><br><span class=\"line\">        .init = flip_init,</span><br><span class=\"line\">        .uninit = flip_uninit,</span><br><span class=\"line\">        FILTER_INPUTS(flip_inputs),</span><br><span class=\"line\">        FILTER_OUTPUTS(flip_outputs),</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>命令行运行：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">ffmpeg -i test.mp4 -filter_complex &quot;[0:v]flip=duration=5[out];&quot; -map &quot;[out]&quot; flip.mp4</span><br></pre></td></tr></table></figure>\n\n<p> 得到渲染好的视频，前5s是上下翻转的，后面的内容正常。</p>\n<p>相比于最简单的 AVFilter 多了几个实现：</p>\n<ol>\n<li><p><strong><code>AVOption flip_options</code></strong></p>\n<p>用于设置翻转持续时间的选项，外部命令配置可选输入<code>duration=5</code>，会自动对数据合法性进行校验。参数类型为 <code>AV_OPT_TYPE_INT</code>，默认值为 0，取值范围为 0 到 <code>INT_MAX</code>。<code>.flags</code> 设置为 <code>AV_OPT_FLAG_FILTERING_PARAM</code>，表示这是一个过滤参数。</p>\n</li>\n<li><p><strong><code>.priv_class</code></strong>  </p>\n<p>配置的<code>flip_class</code>实际是通过 <code>AVFILTER_DEFINE_CLASS(flip);</code> 宏实现的一个声明：见：<a href=\"https://github.com/FFmpeg/FFmpeg/blob/release/6.1/libavfilter/internal.h#L311\">internal.h#AVFILTER_DEFINE_CLASS_EXT</a></p>\n</li>\n<li><p><strong><code>**init</code>&amp; <code>uninit</code></strong></p>\n<p>滤镜在初始化或者释放资源的时候将会调用</p>\n</li>\n<li><p><strong><code>activate</code></strong></p>\n<p>这个函数首先获取输入帧，然后调用 <code>flip_frame</code> 函数进行翻转操作，并将处理后的帧放入输出链接。如果没有输入帧，它会请求一个新的输入帧。最后，它会确认输入链接的状态，并根据需要设置输出链接的状态。</p>\n</li>\n</ol>\n<p>这个例子相比最简单的 filter 使用了 <code>activate</code> 函数 用于帧渲染，而不是使用 <code>filter_frame</code>去渲染，这两个方法有什么区别于联系呢？查看：<a href=\"##filter_frame()%E5%92%8Cactivate()%E5%87%BD%E6%95%B0\">filter_frame和activate方法</a></p>\n<p>也能通过 <code>filter_frame</code>实现，对代码部分逻辑更新更改：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">const</span> AVFilterPad flip_inputs[] = &#123;</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">                .name = <span class=\"string\">&quot;default&quot;</span>,</span><br><span class=\"line\">                .type = AVMEDIA_TYPE_VIDEO,</span><br><span class=\"line\">                .filter_frame = filter_frame, <span class=\"comment\">//添加filter_frame 实现</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">const</span> AVFilter ff_vf_flip = &#123;</span><br><span class=\"line\">       ……</span><br><span class=\"line\">        .priv_class = &amp;flip_class,</span><br><span class=\"line\">       <span class=\"comment\">// .activate      = activate,</span></span><br><span class=\"line\">        .init = flip_init,</span><br><span class=\"line\">       ……</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">int</span> <span class=\"title function_\">filter_frame</span><span class=\"params\">(AVFilterLink *inlink, AVFrame *in)</span> &#123;</span><br><span class=\"line\">    AVFilterContext *ctx = inlink-&gt;dst;</span><br><span class=\"line\">    FlipContext *s = ctx-&gt;priv;</span><br><span class=\"line\">    AVFilterLink *outlink = ctx-&gt;outputs[<span class=\"number\">0</span>];</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int64_t</span> pts = in-&gt;pts;</span><br><span class=\"line\">    <span class=\"comment\">// 将时间戳（pts）转化以秒为单位的时间戳</span></span><br><span class=\"line\">    <span class=\"type\">float</span> time_s = TS2T(pts, inlink-&gt;time_base);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (time_s &gt; s-&gt;duration) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 超过对应的时间则直接输出in_frame</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> ff_filter_frame(outlink, in);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        av_log(<span class=\"literal\">NULL</span>, AV_LOG_ERROR, <span class=\"string\">&quot;time_s s: %f.\\n&quot;</span>, time_s);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    AVFrame *out = flip_frame(ctx, in);</span><br><span class=\"line\">    <span class=\"comment\">// 释放输入帧</span></span><br><span class=\"line\">    av_frame_free(&amp;in);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 将输出帧传递给下一个滤镜</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> ff_filter_frame(outlink, out);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>命令行运行，得到的输出结果是一样的。</p>\n<h2 id=\"filter-frame-和activate-函数\"><a href=\"#filter-frame-和activate-函数\" class=\"headerlink\" title=\"filter_frame()和activate()函数\"></a>filter_frame()和activate()函数</h2><p>对于这点查了相关资料，看看源码相关的实现</p>\n<p>参考：<a href=\"https://www.ffmpeg.org/doxygen/5.0/filter__design_8txt.html\">https://www.ffmpeg.org/doxygen/5.0/filter__design_8txt.html</a></p>\n<blockquote>\n<p>The purpose of these rules is to ensure that frames flow in the filter graph without getting stuck and accumulating somewhere. Simple filters that output one frame for each input frame should not have to worry about it. There are two design for filters:one using the  <a href=\"https://www.ffmpeg.org/doxygen/5.0/vsink__nullsink_8c.html#aaa9a0e0f9de1464941d86a984cf77d37\">filter_frame</a>() and <a href=\"https://www.ffmpeg.org/doxygen/5.0/vsrc__mptestsrc_8c.html#a72949c8fcad3f201712a3569fc6888cb\">request_frame</a>() callbacks and the other using the activate() callback. The design using filter_frame() and request_frame() is legacy, but it is suitable for filters that have a single input and process one frame at a time. New filters with several inputs, that treat several frames at a time or that require a special treatment at EOF should probably use the design using activate(). activate ——– This method is called when something must be done in a filter</p>\n</blockquote>\n<p>大意，实现滤镜有两种实现方式：</p>\n<ul>\n<li><p><strong><code>filter_frame()</code></strong></p>\n<p>可以被认为是历史遗留产物。在早期的 AVFilter 设计中，<code>filter_frame()</code> 和 <code>request_frame()</code> 是主要用于处理输入帧和请求输出帧的回调函数。这种设计适用于简单的过滤器，例如单输入且每次处理一个帧的过滤器。</p>\n</li>\n<li><p><strong><code>activate()</code></strong></p>\n<p>随着 ffmpeg 和 AVFilter 的发展，处理需求变得越来越复杂，例如需要处理多个输入、一次处理多个帧或在文件结束（EOF）时进行特殊处理等。为了满足这些需求，引入了 <code>activate()</code> 函数，它提供了更灵活和强大的处理能力。因此，虽然 <code>filter_frame()</code> 在某些简单场景下仍然可以使用，但对于新的或复杂的过滤器，建议使用 <code>activate()</code> 函数。</p>\n</li>\n</ul>\n<p>如果两个方法都实现了，那他们谁会先执行呢？</p>\n<p>对应的源码处理逻辑： <a href=\"https://github.com/FFmpeg/FFmpeg/blob/release/6.1/libavfilter/avfilter.c#L1322\">avfilter.c</a></p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">ff_filter_activate</span><span class=\"params\">(AVFilterContext *filter)</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> ret;</span><br><span class=\"line\">\t\t……</span><br><span class=\"line\">    ret = filter-&gt;filter-&gt;activate ? filter-&gt;filter-&gt;activate(filter) :</span><br><span class=\"line\">          ff_filter_activate_default(filter);</span><br><span class=\"line\">  \t……</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ret;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>如果配置了activate() 函数则执行，否则执行 ff_filter_activate_default()-&gt;ff_filter_frame_to_filter()-&gt;ff_filter_frame_framed() 最终执行到配置的 filter_frame() 方法。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">int</span> <span class=\"title function_\">ff_filter_frame_framed</span><span class=\"params\">(AVFilterLink *link, AVFrame *frame)</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> (*filter_frame)(AVFilterLink *, AVFrame *);</span><br><span class=\"line\">    AVFilterContext *dstctx = link-&gt;dst;</span><br><span class=\"line\">    AVFilterPad *dst = link-&gt;dstpad;</span><br><span class=\"line\">    <span class=\"type\">int</span> ret;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!(filter_frame = dst-&gt;filter_frame))</span><br><span class=\"line\">        filter_frame = default_filter_frame;</span><br><span class=\"line\">    ……</span><br><span class=\"line\">    ret = filter_frame(link, frame);  <span class=\"comment\">// 最终调用到的地方</span></span><br><span class=\"line\">    link-&gt;frame_count_out++;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ret;</span><br><span class=\"line\">fail:</span><br><span class=\"line\">    ……</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>本文介绍了 FFmpeg 滤镜开发的整体流程，如何编写 filter.c 文件，并以一个最简单的 AVFilter 和一个较为复杂的 AVFilter 为例，解析了滤镜开发的具体步骤和代码实现，并介绍了 filter_frame() 和 activate() 函数的区别与联系。</p>\n<p>在滤镜开发过程中，需要注意的是，filter_frame() 和 activate() 函数的使用取决于滤镜的复杂性。对于简单的滤镜，可以使用 filter_frame() 函数；而对于需要处理多个输入、一次处理多个帧或在文件结束（EOF）时进行特殊处理的复杂滤镜，建议使用 activate() 函数。</p>\n<p>文中的源码可以查看：<a href=\"https://github.com/VomPom/FFmpeg/commit/9176f58ae60e0b70e5708b25017f374deac9fae7\">add most simplest  AVFilter and a simple video flip filter.</a></p>\n<h3 id=\"参考：\"><a href=\"#参考：\" class=\"headerlink\" title=\"参考：\"></a>参考：</h3><p><a href=\"https://www.cnblogs.com/TaigaCon/p/10171464.html\">https://www.cnblogs.com/TaigaCon/p/10171464.html</a></p>\n<p><a href=\"https://www.cnblogs.com/ranson7zop/p/7728639.html\">https://www.cnblogs.com/ranson7zop/p/7728639.html</a></p>\n<p><a href=\"https://www.ffmpeg.org/doxygen/5.0/filter__design_8txt.html\">https://www.ffmpeg.org/doxygen/5.0/filter__design_8txt.html</a></p>\n","cover":null,"images":[],"content":"<p>此前在做  ffmpeg+某个第三库作为 filter 的集成，第三库是做AE特效相关的，与 ffmpeg 结合能让视频渲染效果大大提升。整体流程将第三方库作为 ffmpeg 的一个filter 形式进行结合，其中就涉及到 ffmpeg 的 filter 开发，本文即 对ffmpeg 的滤镜开发流程作一个总结。本文以实现一个视频垂直翻转的 filter 为例，ffmpeg 源码基于<a href=\"https://github.com/FFmpeg/FFmpeg/tree/release/6.1\">FFmpeg6.1</a> </p>\n<h2 id=\"实现自定义-Filter-流程\"><a href=\"#实现自定义-Filter-流程\" class=\"headerlink\" title=\"实现自定义 Filter 流程\"></a>实现自定义 Filter 流程</h2><ul>\n<li><p>编写 filter.c 文件</p>\n<p>一般视频滤镜以 vf_ 为前缀，视频滤镜以 af_ 为前缀，放在libavfilter目录下，参考其他 filter 代码逻辑，模块化配置相关参数，本文例以 vf_flip.c 实现视频的上下翻转</p>\n</li>\n<li><p>在 <code>libavfilter/allfilters.c</code> 注册</p>\n<p>例如：extern const AVFilter ff_vf_flip;  <code>ff_vf_flip</code>就是在 <code>vf_flip.c</code>的 filter 注册名称</p>\n</li>\n<li><p>修改 <code>libavfilter/Makefile</code> 添加编译配置： </p>\n<p>例如：OBJS-$(CONFIG_FLIP_FILTER)                   +&#x3D; vf_flip.o</p>\n</li>\n<li><p>编译打包</p>\n</li>\n</ul>\n<h2 id=\"编写-filter-c-文件\"><a href=\"#编写-filter-c-文件\" class=\"headerlink\" title=\"编写 filter.c 文件\"></a>编写 filter.c 文件</h2><h3 id=\"AVFilter主体\"><a href=\"#AVFilter主体\" class=\"headerlink\" title=\"AVFilter主体\"></a>AVFilter主体</h3><figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">AVFilter</span> &#123;</span></span><br><span class=\"line\">  <span class=\"type\">const</span> <span class=\"type\">char</span> *name;</span><br><span class=\"line\">  <span class=\"type\">const</span> <span class=\"type\">char</span> *description;</span><br><span class=\"line\">  <span class=\"type\">const</span> AVFilterPad *inputs;</span><br><span class=\"line\">  <span class=\"type\">const</span> AVFilterPad *outputs;</span><br><span class=\"line\">  <span class=\"type\">const</span> AVClass *priv_class;</span><br><span class=\"line\">  <span class=\"type\">int</span> flags;</span><br><span class=\"line\">  <span class=\"type\">int</span> (*preinit)(AVFilterContext *ctx);</span><br><span class=\"line\">  <span class=\"type\">int</span> (*init)(AVFilterContext *ctx);</span><br><span class=\"line\">  <span class=\"type\">int</span> (*init_dict)(AVFilterContext *ctx, AVDictionary **options);</span><br><span class=\"line\">  <span class=\"type\">void</span> (*uninit)(AVFilterContext *ctx);</span><br><span class=\"line\">  <span class=\"type\">int</span> (*query_formats)(AVFilterContext *);</span><br><span class=\"line\">  <span class=\"type\">int</span> priv_size;   </span><br><span class=\"line\">  <span class=\"type\">int</span> flags_internal; </span><br><span class=\"line\">  <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">AVFilter</span> *<span class=\"title\">next</span>;</span></span><br><span class=\"line\">  <span class=\"type\">int</span> (*process_command)(AVFilterContext *, <span class=\"type\">const</span> <span class=\"type\">char</span> *cmd, <span class=\"type\">const</span> <span class=\"type\">char</span> *arg, <span class=\"type\">char</span> *res, <span class=\"type\">int</span> res_len, <span class=\"type\">int</span> flags);</span><br><span class=\"line\">  <span class=\"type\">int</span> (*init_opaque)(AVFilterContext *ctx, <span class=\"type\">void</span> *opaque);</span><br><span class=\"line\">  <span class=\"type\">int</span> (*activate)(AVFilterContext *ctx);</span><br><span class=\"line\">&#125; AVFilter;</span><br></pre></td></tr></table></figure>\n\n<p>具体里面的属性作用可以参考：<a href=\"https://www.cnblogs.com/TaigaCon/p/10171464.html\">[ffmpeg] 定制滤波器</a>，可以根据需求实现里面的相关函数，接下来以一个最简单的 Filter 和一个较复杂一点的 Filter 举例。</p>\n<h3 id=\"最简单的-AVFilter\"><a href=\"#最简单的-AVFilter\" class=\"headerlink\" title=\"最简单的 AVFilter\"></a>最简单的 AVFilter</h3><figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> &#123;</span></span><br><span class=\"line\">    <span class=\"type\">const</span> AVClass *<span class=\"class\"><span class=\"keyword\">class</span>;</span></span><br><span class=\"line\">&#125; NoopContext;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">int</span> <span class=\"title function_\">filter_frame</span><span class=\"params\">(AVFilterLink *link, AVFrame *frame)</span> &#123;</span><br><span class=\"line\">    av_log(<span class=\"literal\">NULL</span>, AV_LOG_INFO, <span class=\"string\">&quot;filter frame pts:%lld\\n&quot;</span>, frame-&gt;pts);</span><br><span class=\"line\">    NoopContext *noopContext = link-&gt;dst-&gt;priv;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ff_filter_frame(link-&gt;dst-&gt;outputs[<span class=\"number\">0</span>], frame);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">const</span> AVFilterPad noop_inputs[] = &#123;</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">                .name         = <span class=\"string\">&quot;default&quot;</span>,</span><br><span class=\"line\">                .type         = AVMEDIA_TYPE_VIDEO,</span><br><span class=\"line\">                .filter_frame = filter_frame,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">const</span> AVFilterPad noop_outputs[] = &#123;</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">                .name = <span class=\"string\">&quot;default&quot;</span>,</span><br><span class=\"line\">                .type = AVMEDIA_TYPE_VIDEO,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"type\">const</span> AVFilter ff_vf_noop = &#123;</span><br><span class=\"line\">        .name          = <span class=\"string\">&quot;noop&quot;</span>,</span><br><span class=\"line\">        .description   = NULL_IF_CONFIG_SMALL(<span class=\"string\">&quot;Pass the input video unchanged.&quot;</span>),</span><br><span class=\"line\">        .priv_size     = <span class=\"keyword\">sizeof</span>(NoopContext),</span><br><span class=\"line\">        FILTER_INPUTS(noop_inputs),</span><br><span class=\"line\">        FILTER_OUTPUTS(noop_outputs),</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>命令行运行：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ffmpeg -i test.mp4 -vf &quot;noop&quot; noop.mp4</span><br></pre></td></tr></table></figure>\n\n<p> 正常输出文件（对原片没有做任何更改）,这个 filter 的作用是将输入的视频帧不做任何处理地传递给下一个过滤器，在处理每帧的时候会打印处理的 PTS，麻雀虽小五脏俱全，它包含了一个 AVFilter 基础的结构：</p>\n<ol>\n<li><p><strong><code>NoopContext</code></strong></p>\n<p>这是一个简单的结构体，包含一个指向 AVClass 的指针。在这个例子中，实际上没有使用到 NoopContext 结构体的任何成员，因为这个过滤器没有需要存储的私有数据。</p>\n</li>\n<li><p><strong><code>filter_frame</code></strong> </p>\n<p>这个函数的作用是处理输入的视频帧。在这个例子中，它只是打印帧的 PTS（Presentation Time Stamp，显示时间戳）并将帧传递给下一个过滤器，不对帧做任何修改。</p>\n</li>\n<li><p><strong><code>noop_inputs</code> 和 <code>noop_outputs</code></strong></p>\n<p>这两个数组定义了过滤器的输入和输出 Pad。在这个例子中，输入 Pad 类型为 AVMEDIA_TYPE_VIDEO，并关联了 <code>filter_frame</code> 函数。输出 Pad 也是 AVMEDIA_TYPE_VIDEO 类型，但没有关联任何函数，因为输出直接由 <code>filter_frame</code> 函数处理。</p>\n</li>\n<li><p><strong><code>ff_vf_noop</code></strong></p>\n<p>这是一个 AVFilter 结构体实例，包含了过滤器的名称、描述、私有数据大小以及输入和输出 Pad。在这个例子中，过滤器的名称为 “noop”，描述为 “Pass the input video unchanged.”，这也就是在执行：<code>ffmpeg -filters</code> 看到的 Filter描述内容。</p>\n</li>\n</ol>\n<p>接下来看一个稍微复杂的一个 AVFilter，实现一个视频的上下翻转</p>\n<h3 id=\"复杂一点的-AVFilter\"><a href=\"#复杂一点的-AVFilter\" class=\"headerlink\" title=\"复杂一点的 AVFilter\"></a>复杂一点的 AVFilter</h3><figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">FlipContext</span> &#123;</span></span><br><span class=\"line\">    <span class=\"type\">const</span> AVClass *<span class=\"class\"><span class=\"keyword\">class</span>;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> duration;</span><br><span class=\"line\">&#125; FlipContext;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> OFFSET(x) offsetof(FlipContext, x)</span></span><br><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">const</span> AVOption flip_options[] = &#123;</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;duration&quot;</span>, <span class=\"string\">&quot;set flip duration&quot;</span>, OFFSET(duration), AV_OPT_TYPE_INT, &#123;.i64 = <span class=\"number\">0</span>&#125;, <span class=\"number\">0</span>, INT_MAX, .flags = AV_OPT_FLAG_FILTERING_PARAM&#125;,</span><br><span class=\"line\">        &#123;<span class=\"literal\">NULL</span>&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">static</span> av_cold <span class=\"type\">int</span> <span class=\"title function_\">flip_init</span><span class=\"params\">(AVFilterContext *ctx)</span> &#123;</span><br><span class=\"line\">    FlipContext *context = ctx-&gt;priv;</span><br><span class=\"line\">    av_log(<span class=\"literal\">NULL</span>, AV_LOG_ERROR, <span class=\"string\">&quot;Input duration: %d.\\n&quot;</span>, context-&gt;duration);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">static</span> av_cold <span class=\"type\">void</span> <span class=\"title function_\">flip_uninit</span><span class=\"params\">(AVFilterContext *ctx)</span> &#123;</span><br><span class=\"line\">    FlipContext *context = ctx-&gt;priv;</span><br><span class=\"line\">    <span class=\"comment\">// no-op 本例无需释放滤镜实例分配的内存、关闭文件、资源等</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 对输入的 AVFrame 进行翻转</span></span><br><span class=\"line\"><span class=\"type\">static</span> AVFrame *<span class=\"title function_\">flip_frame</span><span class=\"params\">(AVFilterContext *ctx, AVFrame *in_frame)</span> &#123;</span><br><span class=\"line\"> \t\tAVFilterLink *inlink = ctx-&gt;inputs[<span class=\"number\">0</span>];</span><br><span class=\"line\">    FlipContext *s = ctx-&gt;priv;</span><br><span class=\"line\">    <span class=\"type\">int64_t</span> pts = in_frame-&gt;pts;</span><br><span class=\"line\">    <span class=\"comment\">// 将时间戳（pts）转化以秒为单位的时间戳</span></span><br><span class=\"line\">    <span class=\"type\">float</span> time_s = TS2T(pts, inlink-&gt;time_base);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (time_s &gt; s-&gt;duration) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 超过对应的时间则直接输出in_frame</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> in_frame;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 创建输出帧并分配内存</span></span><br><span class=\"line\">    AVFrame *out_frame = av_frame_alloc();</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!out_frame) &#123;</span><br><span class=\"line\">        av_frame_free(&amp;in_frame);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out_frame;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 设置输出帧的属性</span></span><br><span class=\"line\">    out_frame-&gt;format = in_frame-&gt;format;</span><br><span class=\"line\">    out_frame-&gt;width = in_frame-&gt;width;</span><br><span class=\"line\">    out_frame-&gt;height = in_frame-&gt;height;</span><br><span class=\"line\">    out_frame-&gt;pts = in_frame-&gt;pts;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 分配输出帧的数据缓冲区</span></span><br><span class=\"line\">    <span class=\"type\">int</span> ret = av_frame_get_buffer(out_frame, <span class=\"number\">32</span>);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (ret &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        av_frame_free(&amp;in_frame);</span><br><span class=\"line\">        av_frame_free(&amp;out_frame);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out_frame;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 这个示例仅适用于 YUV 格式的视频。对于其他格式（如 RGB）</span></span><br><span class=\"line\">    <span class=\"comment\">// 翻转输入帧的数据到输出帧</span></span><br><span class=\"line\">    <span class=\"comment\">// 翻转了 Y 分量，然后翻转了 U 和 V 分量</span></span><br><span class=\"line\">    <span class=\"comment\">//</span></span><br><span class=\"line\">    <span class=\"type\">uint8_t</span> *src_y = in_frame-&gt;data[<span class=\"number\">0</span>];</span><br><span class=\"line\">    <span class=\"type\">uint8_t</span> *src_u = in_frame-&gt;data[<span class=\"number\">1</span>];</span><br><span class=\"line\">    <span class=\"type\">uint8_t</span> *src_v = in_frame-&gt;data[<span class=\"number\">2</span>];</span><br><span class=\"line\">    <span class=\"type\">uint8_t</span> *dst_y = out_frame-&gt;data[<span class=\"number\">0</span>] + (in_frame-&gt;height - <span class=\"number\">1</span>) * out_frame-&gt;linesize[<span class=\"number\">0</span>];</span><br><span class=\"line\">    <span class=\"type\">uint8_t</span> *dst_u = out_frame-&gt;data[<span class=\"number\">1</span>] + (in_frame-&gt;height / <span class=\"number\">2</span> - <span class=\"number\">1</span>) * out_frame-&gt;linesize[<span class=\"number\">1</span>];</span><br><span class=\"line\">    <span class=\"type\">uint8_t</span> *dst_v = out_frame-&gt;data[<span class=\"number\">2</span>] + (in_frame-&gt;height / <span class=\"number\">2</span> - <span class=\"number\">1</span>) * out_frame-&gt;linesize[<span class=\"number\">2</span>];</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; in_frame-&gt;height; i++) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">memcpy</span>(dst_y, src_y, in_frame-&gt;width);</span><br><span class=\"line\">        src_y += in_frame-&gt;linesize[<span class=\"number\">0</span>];</span><br><span class=\"line\">        dst_y -= out_frame-&gt;linesize[<span class=\"number\">0</span>];</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (i &lt; in_frame-&gt;height / <span class=\"number\">2</span>) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">memcpy</span>(dst_u, src_u, in_frame-&gt;width / <span class=\"number\">2</span>);</span><br><span class=\"line\">            <span class=\"built_in\">memcpy</span>(dst_v, src_v, in_frame-&gt;width / <span class=\"number\">2</span>);</span><br><span class=\"line\">            src_u += in_frame-&gt;linesize[<span class=\"number\">1</span>];</span><br><span class=\"line\">            src_v += in_frame-&gt;linesize[<span class=\"number\">2</span>];</span><br><span class=\"line\">            dst_u -= out_frame-&gt;linesize[<span class=\"number\">1</span>];</span><br><span class=\"line\">            dst_v -= out_frame-&gt;linesize[<span class=\"number\">2</span>];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> out_frame;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">int</span> <span class=\"title function_\">activate</span><span class=\"params\">(AVFilterContext *ctx)</span> &#123;</span><br><span class=\"line\">    AVFilterLink *inlink = ctx-&gt;inputs[<span class=\"number\">0</span>];</span><br><span class=\"line\">    AVFilterLink *outlink = ctx-&gt;outputs[<span class=\"number\">0</span>];</span><br><span class=\"line\">    AVFrame *in_frame = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    AVFrame *out_frame = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> ret = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"comment\">// 获取输入帧</span></span><br><span class=\"line\">    ret = ff_inlink_consume_frame(inlink, &amp;in_frame);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (ret &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ret;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 如果有输入帧，进行翻转处理</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (in_frame) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 对输出帧进行上下翻转处理</span></span><br><span class=\"line\">        out_frame = flip_frame(ctx, in_frame);</span><br><span class=\"line\">        <span class=\"comment\">// 将处理后的帧放入输出缓冲区</span></span><br><span class=\"line\">        ret = ff_filter_frame(outlink, out_frame);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (ret &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            av_frame_free(&amp;out_frame);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ret;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 如果没有输入帧，尝试请求一个新的输入帧</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!in_frame) &#123;</span><br><span class=\"line\">        ff_inlink_request_frame(inlink);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> status;</span><br><span class=\"line\">    <span class=\"type\">int64_t</span> pts;</span><br><span class=\"line\">    ret = ff_inlink_acknowledge_status(inlink, &amp;status, &amp;pts);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (ret &lt; <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ret;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (status == AVERROR_EOF) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 输入链接已经结束，设置输出链接的状态为 EOF</span></span><br><span class=\"line\">        ff_outlink_set_status(outlink, AVERROR_EOF, pts);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">AVFILTER_DEFINE_CLASS(flip);</span><br><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">const</span> AVFilterPad flip_inputs[] = &#123;</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">                .name = <span class=\"string\">&quot;default&quot;</span>,</span><br><span class=\"line\">                .type = AVMEDIA_TYPE_VIDEO,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">const</span> AVFilterPad flip_outputs[] = &#123;</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">                .name = <span class=\"string\">&quot;default&quot;</span>,</span><br><span class=\"line\">                .type = AVMEDIA_TYPE_VIDEO,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"type\">const</span> AVFilter ff_vf_flip = &#123;</span><br><span class=\"line\">        .name = <span class=\"string\">&quot;flip&quot;</span>,</span><br><span class=\"line\">        .description = NULL_IF_CONFIG_SMALL(<span class=\"string\">&quot;Flip the input video.&quot;</span>),</span><br><span class=\"line\">        .priv_size = <span class=\"keyword\">sizeof</span>(FlipContext),</span><br><span class=\"line\">        .priv_class = &amp;flip_class,</span><br><span class=\"line\">        .activate      = activate,</span><br><span class=\"line\">        .init = flip_init,</span><br><span class=\"line\">        .uninit = flip_uninit,</span><br><span class=\"line\">        FILTER_INPUTS(flip_inputs),</span><br><span class=\"line\">        FILTER_OUTPUTS(flip_outputs),</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>命令行运行：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">ffmpeg -i test.mp4 -filter_complex &quot;[0:v]flip=duration=5[out];&quot; -map &quot;[out]&quot; flip.mp4</span><br></pre></td></tr></table></figure>\n\n<p> 得到渲染好的视频，前5s是上下翻转的，后面的内容正常。</p>\n<p>相比于最简单的 AVFilter 多了几个实现：</p>\n<ol>\n<li><p><strong><code>AVOption flip_options</code></strong></p>\n<p>用于设置翻转持续时间的选项，外部命令配置可选输入<code>duration=5</code>，会自动对数据合法性进行校验。参数类型为 <code>AV_OPT_TYPE_INT</code>，默认值为 0，取值范围为 0 到 <code>INT_MAX</code>。<code>.flags</code> 设置为 <code>AV_OPT_FLAG_FILTERING_PARAM</code>，表示这是一个过滤参数。</p>\n</li>\n<li><p><strong><code>.priv_class</code></strong>  </p>\n<p>配置的<code>flip_class</code>实际是通过 <code>AVFILTER_DEFINE_CLASS(flip);</code> 宏实现的一个声明：见：<a href=\"https://github.com/FFmpeg/FFmpeg/blob/release/6.1/libavfilter/internal.h#L311\">internal.h#AVFILTER_DEFINE_CLASS_EXT</a></p>\n</li>\n<li><p><strong><code>**init</code>&amp; <code>uninit</code></strong></p>\n<p>滤镜在初始化或者释放资源的时候将会调用</p>\n</li>\n<li><p><strong><code>activate</code></strong></p>\n<p>这个函数首先获取输入帧，然后调用 <code>flip_frame</code> 函数进行翻转操作，并将处理后的帧放入输出链接。如果没有输入帧，它会请求一个新的输入帧。最后，它会确认输入链接的状态，并根据需要设置输出链接的状态。</p>\n</li>\n</ol>\n<p>这个例子相比最简单的 filter 使用了 <code>activate</code> 函数 用于帧渲染，而不是使用 <code>filter_frame</code>去渲染，这两个方法有什么区别于联系呢？查看：<a href=\"##filter_frame()%E5%92%8Cactivate()%E5%87%BD%E6%95%B0\">filter_frame和activate方法</a></p>\n<p>也能通过 <code>filter_frame</code>实现，对代码部分逻辑更新更改：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">const</span> AVFilterPad flip_inputs[] = &#123;</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">                .name = <span class=\"string\">&quot;default&quot;</span>,</span><br><span class=\"line\">                .type = AVMEDIA_TYPE_VIDEO,</span><br><span class=\"line\">                .filter_frame = filter_frame, <span class=\"comment\">//添加filter_frame 实现</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">const</span> AVFilter ff_vf_flip = &#123;</span><br><span class=\"line\">       ……</span><br><span class=\"line\">        .priv_class = &amp;flip_class,</span><br><span class=\"line\">       <span class=\"comment\">// .activate      = activate,</span></span><br><span class=\"line\">        .init = flip_init,</span><br><span class=\"line\">       ……</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">int</span> <span class=\"title function_\">filter_frame</span><span class=\"params\">(AVFilterLink *inlink, AVFrame *in)</span> &#123;</span><br><span class=\"line\">    AVFilterContext *ctx = inlink-&gt;dst;</span><br><span class=\"line\">    FlipContext *s = ctx-&gt;priv;</span><br><span class=\"line\">    AVFilterLink *outlink = ctx-&gt;outputs[<span class=\"number\">0</span>];</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int64_t</span> pts = in-&gt;pts;</span><br><span class=\"line\">    <span class=\"comment\">// 将时间戳（pts）转化以秒为单位的时间戳</span></span><br><span class=\"line\">    <span class=\"type\">float</span> time_s = TS2T(pts, inlink-&gt;time_base);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (time_s &gt; s-&gt;duration) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 超过对应的时间则直接输出in_frame</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> ff_filter_frame(outlink, in);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        av_log(<span class=\"literal\">NULL</span>, AV_LOG_ERROR, <span class=\"string\">&quot;time_s s: %f.\\n&quot;</span>, time_s);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    AVFrame *out = flip_frame(ctx, in);</span><br><span class=\"line\">    <span class=\"comment\">// 释放输入帧</span></span><br><span class=\"line\">    av_frame_free(&amp;in);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 将输出帧传递给下一个滤镜</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> ff_filter_frame(outlink, out);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>命令行运行，得到的输出结果是一样的。</p>\n<h2 id=\"filter-frame-和activate-函数\"><a href=\"#filter-frame-和activate-函数\" class=\"headerlink\" title=\"filter_frame()和activate()函数\"></a>filter_frame()和activate()函数</h2><p>对于这点查了相关资料，看看源码相关的实现</p>\n<p>参考：<a href=\"https://www.ffmpeg.org/doxygen/5.0/filter__design_8txt.html\">https://www.ffmpeg.org/doxygen/5.0/filter__design_8txt.html</a></p>\n<blockquote>\n<p>The purpose of these rules is to ensure that frames flow in the filter graph without getting stuck and accumulating somewhere. Simple filters that output one frame for each input frame should not have to worry about it. There are two design for filters:one using the  <a href=\"https://www.ffmpeg.org/doxygen/5.0/vsink__nullsink_8c.html#aaa9a0e0f9de1464941d86a984cf77d37\">filter_frame</a>() and <a href=\"https://www.ffmpeg.org/doxygen/5.0/vsrc__mptestsrc_8c.html#a72949c8fcad3f201712a3569fc6888cb\">request_frame</a>() callbacks and the other using the activate() callback. The design using filter_frame() and request_frame() is legacy, but it is suitable for filters that have a single input and process one frame at a time. New filters with several inputs, that treat several frames at a time or that require a special treatment at EOF should probably use the design using activate(). activate ——– This method is called when something must be done in a filter</p>\n</blockquote>\n<p>大意，实现滤镜有两种实现方式：</p>\n<ul>\n<li><p><strong><code>filter_frame()</code></strong></p>\n<p>可以被认为是历史遗留产物。在早期的 AVFilter 设计中，<code>filter_frame()</code> 和 <code>request_frame()</code> 是主要用于处理输入帧和请求输出帧的回调函数。这种设计适用于简单的过滤器，例如单输入且每次处理一个帧的过滤器。</p>\n</li>\n<li><p><strong><code>activate()</code></strong></p>\n<p>随着 ffmpeg 和 AVFilter 的发展，处理需求变得越来越复杂，例如需要处理多个输入、一次处理多个帧或在文件结束（EOF）时进行特殊处理等。为了满足这些需求，引入了 <code>activate()</code> 函数，它提供了更灵活和强大的处理能力。因此，虽然 <code>filter_frame()</code> 在某些简单场景下仍然可以使用，但对于新的或复杂的过滤器，建议使用 <code>activate()</code> 函数。</p>\n</li>\n</ul>\n<p>如果两个方法都实现了，那他们谁会先执行呢？</p>\n<p>对应的源码处理逻辑： <a href=\"https://github.com/FFmpeg/FFmpeg/blob/release/6.1/libavfilter/avfilter.c#L1322\">avfilter.c</a></p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">ff_filter_activate</span><span class=\"params\">(AVFilterContext *filter)</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> ret;</span><br><span class=\"line\">\t\t……</span><br><span class=\"line\">    ret = filter-&gt;filter-&gt;activate ? filter-&gt;filter-&gt;activate(filter) :</span><br><span class=\"line\">          ff_filter_activate_default(filter);</span><br><span class=\"line\">  \t……</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ret;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>如果配置了activate() 函数则执行，否则执行 ff_filter_activate_default()-&gt;ff_filter_frame_to_filter()-&gt;ff_filter_frame_framed() 最终执行到配置的 filter_frame() 方法。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">static</span> <span class=\"type\">int</span> <span class=\"title function_\">ff_filter_frame_framed</span><span class=\"params\">(AVFilterLink *link, AVFrame *frame)</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> (*filter_frame)(AVFilterLink *, AVFrame *);</span><br><span class=\"line\">    AVFilterContext *dstctx = link-&gt;dst;</span><br><span class=\"line\">    AVFilterPad *dst = link-&gt;dstpad;</span><br><span class=\"line\">    <span class=\"type\">int</span> ret;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!(filter_frame = dst-&gt;filter_frame))</span><br><span class=\"line\">        filter_frame = default_filter_frame;</span><br><span class=\"line\">    ……</span><br><span class=\"line\">    ret = filter_frame(link, frame);  <span class=\"comment\">// 最终调用到的地方</span></span><br><span class=\"line\">    link-&gt;frame_count_out++;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ret;</span><br><span class=\"line\">fail:</span><br><span class=\"line\">    ……</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>本文介绍了 FFmpeg 滤镜开发的整体流程，如何编写 filter.c 文件，并以一个最简单的 AVFilter 和一个较为复杂的 AVFilter 为例，解析了滤镜开发的具体步骤和代码实现，并介绍了 filter_frame() 和 activate() 函数的区别与联系。</p>\n<p>在滤镜开发过程中，需要注意的是，filter_frame() 和 activate() 函数的使用取决于滤镜的复杂性。对于简单的滤镜，可以使用 filter_frame() 函数；而对于需要处理多个输入、一次处理多个帧或在文件结束（EOF）时进行特殊处理的复杂滤镜，建议使用 activate() 函数。</p>\n<p>文中的源码可以查看：<a href=\"https://github.com/VomPom/FFmpeg/commit/9176f58ae60e0b70e5708b25017f374deac9fae7\">add most simplest  AVFilter and a simple video flip filter.</a></p>\n<h3 id=\"参考：\"><a href=\"#参考：\" class=\"headerlink\" title=\"参考：\"></a>参考：</h3><p><a href=\"https://www.cnblogs.com/TaigaCon/p/10171464.html\">https://www.cnblogs.com/TaigaCon/p/10171464.html</a></p>\n<p><a href=\"https://www.cnblogs.com/ranson7zop/p/7728639.html\">https://www.cnblogs.com/ranson7zop/p/7728639.html</a></p>\n<p><a href=\"https://www.ffmpeg.org/doxygen/5.0/filter__design_8txt.html\">https://www.ffmpeg.org/doxygen/5.0/filter__design_8txt.html</a></p>\n","categories":[],"tags":[{"name":"FFmpeg","slug":"FFmpeg","api":"api/tags/FFmpeg.json"}],"api":"api/posts/2024/03/07/实现一个自定义FFmpeg-Filter.json"},{"title":"FFmpeg.so 编译总结","slug":"FFmpeg-so-编译整理","date":"2023-01-09T02:36:00.000Z","updated":"2025-05-20T11:46:57.000Z","comments":true,"url":"2023/01/09/FFmpeg-so-编译整理/","excerpt":"<p>此前项目一直使用的 FFmpeg.so 是我从其他团队项目中直接复制过来的，但原来的项目团队不再维护这个库，其中 x264 模块由于一些版权问题需要剔除，所以需要自己重新编译。在编译的过程中踩了很多坑，以及编译 congfigure 有太多的配置，如何减少整体编译出来的大小也是需要花点精力的，本文主要记录编译流程以及相关配置介绍。</p>\n<h2 id=\"编译介绍\"><a href=\"#编译介绍\" class=\"headerlink\" title=\"编译介绍\"></a>编译介绍</h2><p>自己编译主要参考<a href=\"https://github.com/Timdk857/Android-Architecture-knowledge-2-/blob/master/Android%20%E9%9F%B3%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97/Android-%E9%9F%B3%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-(%E5%9B%9B)-%E4%B8%80%E9%94%AE%E7%BC%96%E8%AF%91-32-64-%E4%BD%8D-FFmpeg-4-2-2.md\">《一键编译32_64位FFmpeg.4.2.2》</a>，最开始的时候自己一直在 Mac M1 上编译，各种流程也是一比一复刻，但是仍然会有各种问题出现，最常见的就是：</p>\n<blockquote>\n<p>aarch64-linux-android21-clang is unable to create an executable file.<br>C compiler test failed.</p>\n</blockquote>\n<p>我反复检查了自己的 NDK 的配置，确保是正确的，文章也有提及处理方式，但是尝试下来都无效，在网上搜了一大篇解决方式，也都无效。不过我看他们很多都是用 Linux 系统进行的编译，遂改为使用 Linux 编译，再重新尝试，似乎没有那些个奇奇怪怪的错误了，也打出了最终的包，最后的 so 大小也符合要求。</p>\n<h3 id=\"编译环境\"><a href=\"#编译环境\" class=\"headerlink\" title=\"编译环境\"></a>编译环境</h3><ul>\n<li>CentOS 7</li>\n<li><a href=\"https://ffmpeg.org/releases/ffmpeg-4.2.2.tar.bz2\">ffmpeg-4.2.2</a></li>\n<li><a href=\"https://github.com/android/ndk/wiki/Unsupported-Downloads\">android-ndk-r20b-linux-x86_64.zip</a></li>\n</ul>\n<h3 id=\"编译脚本\"><a href=\"#编译脚本\" class=\"headerlink\" title=\"编译脚本\"></a>编译脚本</h3><p>这是我的一份编译脚本，我的需求是进行本地视频抽帧，所以不需要像滤镜、编码、音频相关的配置，只需要视频解码相关的配置，具体配置在下一节有讲解。</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/bin/bash</span></span><br><span class=\"line\">export NDK=.../android<span class=\"literal\">-ndk-r20b</span></span><br><span class=\"line\">TOOLCHAIN=<span class=\"variable\">$NDK</span>/toolchains/llvm/prebuilt/linux<span class=\"literal\">-x86_64</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">build_android</span></span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">./configure \\ </span><br><span class=\"line\"><span class=\"literal\">--prefix</span>=<span class=\"variable\">$PREFIX</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-neon</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-x86asm</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-hwaccels</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-gpl</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-nonfree</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-version3</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-postproc</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-bsfs</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-protocols</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-protocol</span>=file \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-indevs</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-outdevs</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-debug</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-small</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-jni</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-mediacodec</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-decoder</span>=h264_mediacodec \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-swscale</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-static</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-shared</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-filters</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-avfilter</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-encoders</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-muxers</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-demuxers</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-demuxer</span>=avi \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-demuxer</span>=flv \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-demuxer</span>=h261 \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-demuxer</span>=h263 \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-demuxer</span>=h264 \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-demuxer</span>=hevc \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-demuxer</span>=mov \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-demuxer</span>=m4v \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-decoders</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=h263 \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=h263i \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=h263p \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=h264 \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=hevc \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=flv \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=mpeg4 \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-parsers</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-parser</span>=h264 \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-parser</span>=h261 \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-parser</span>=h263 \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-parser</span>=mpeg4video \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-parser</span>=mpegvideo \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-htmlpages</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-manpages</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-podpages</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-txtpages</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-vaapi</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-v4l2-m2m</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-nvdec</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-nvenc</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-ffnvcodec</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-dxva2</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-d3d11va</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-cuvid</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-cuda-llvm</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-cuda-nvcc</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-audiotoolbox</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-amf</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-iconv</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-libxcb</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-libxcb-shm</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-libxcb-xfixes</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-libxcb-shape</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-lzma</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-sdl2</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-securetransport</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-xlib</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-zlib</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-programs</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-ffmpeg</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-ffplay</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-ffprobe</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-avdevice</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-symver</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--cross-prefix</span>=<span class=\"variable\">$CROSS_PREFIX</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--target-os</span>=android \\ </span><br><span class=\"line\"><span class=\"literal\">--arch</span>=<span class=\"variable\">$ARCH</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--cpu</span>=<span class=\"variable\">$CPU</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--cc</span>=<span class=\"variable\">$CC</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--cxx</span>=<span class=\"variable\">$CXX</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-cross-compile</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--sysroot</span>=<span class=\"variable\">$SYSROOT</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--extra-cflags</span>=<span class=\"string\">&quot;-Os -fpic <span class=\"variable\">$OPTIMIZE_CFLAGS</span>&quot;</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--extra-ldflags</span>=<span class=\"string\">&quot;<span class=\"variable\">$ADDI_LDFLAGS</span>&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">make clean</span><br><span class=\"line\">make <span class=\"literal\">-j16</span></span><br><span class=\"line\">make install</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#arm64-v8a</span></span><br><span class=\"line\">ARCH=arm64</span><br><span class=\"line\">CPU=armv8<span class=\"literal\">-a</span></span><br><span class=\"line\">API=<span class=\"number\">21</span></span><br><span class=\"line\">CC=<span class=\"variable\">$TOOLCHAIN</span>/bin/aarch64<span class=\"literal\">-linux-android</span><span class=\"variable\">$API</span><span class=\"literal\">-clang</span></span><br><span class=\"line\">CXX=<span class=\"variable\">$TOOLCHAIN</span>/bin/aarch64<span class=\"literal\">-linux-android</span><span class=\"variable\">$API</span><span class=\"literal\">-clang</span>++</span><br><span class=\"line\">SYSROOT=<span class=\"variable\">$NDK</span>/toolchains/llvm/prebuilt/linux<span class=\"literal\">-x86_64</span>/sysroot</span><br><span class=\"line\">CROSS_PREFIX=<span class=\"variable\">$TOOLCHAIN</span>/bin/aarch64<span class=\"literal\">-linux-android-</span></span><br><span class=\"line\">PREFIX=<span class=\"variable\">$</span>(<span class=\"built_in\">pwd</span>)/android/<span class=\"variable\">$CPU</span></span><br><span class=\"line\">OPTIMIZE_CFLAGS=<span class=\"string\">&quot;-march=<span class=\"variable\">$CPU</span>&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">build_android</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#armv7-a</span></span><br><span class=\"line\">ARCH=arm</span><br><span class=\"line\">CPU=armv7<span class=\"literal\">-a</span></span><br><span class=\"line\">API=<span class=\"number\">21</span></span><br><span class=\"line\">CC=<span class=\"variable\">$TOOLCHAIN</span>/bin/armv7a<span class=\"literal\">-linux-androideabi</span><span class=\"variable\">$API</span><span class=\"literal\">-clang</span></span><br><span class=\"line\">CXX=<span class=\"variable\">$TOOLCHAIN</span>/bin/armv7a<span class=\"literal\">-linux-androideabi</span><span class=\"variable\">$API</span><span class=\"literal\">-clang</span>++</span><br><span class=\"line\">SYSROOT=<span class=\"variable\">$NDK</span>/toolchains/llvm/prebuilt/linux<span class=\"literal\">-x86_64</span>/sysroot</span><br><span class=\"line\">CROSS_PREFIX=<span class=\"variable\">$TOOLCHAIN</span>/bin/arm<span class=\"literal\">-linux-androideabi-</span></span><br><span class=\"line\">PREFIX=<span class=\"variable\">$</span>(<span class=\"built_in\">pwd</span>)/android/<span class=\"variable\">$CPU</span></span><br><span class=\"line\">OPTIMIZE_CFLAGS=<span class=\"string\">&quot;-mfloat-abi=softfp -mfpu=vfp -marm -march=<span class=\"variable\">$CPU</span> &quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">build_android</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"配置介绍\"><a href=\"#配置介绍\" class=\"headerlink\" title=\"配置介绍\"></a>配置介绍</h2><p>通过执行 <code>./configure --help</code> 能得到所有的配置选项，整个配置也非常好理解，通过 list-xxx 可以知道有哪些子选项，然后再通过 <code>--disable-xxx</code>,或者 <code>--enable-xxx</code> 进行关闭或者打开。以解码为例：</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"literal\">--disable-decoders</span>       <span class=\"comment\"># 先关闭所有的解码器</span></span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=flv     <span class=\"comment\"># 然后只打开flv、mpeg4 的支持</span></span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=mpeg4 </span><br></pre></td></tr></table></figure>\n<p>对于<code>--enable-decoder=xxx</code>中的xxx可以通过 <code>./configure --list-decoders</code> 进行查看，同理 <code>encoders</code> <code>demuxers</code> <code>muxers</code> 等都是类似的处理，通过 <code>--help</code> 可以通过 <code>list--xxx</code> 查看不同功能的可以支持的配置，主要有以下：</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"literal\">--list-decoders</span>          show all available decoders</span><br><span class=\"line\"><span class=\"literal\">--list-encoders</span>          show all available encoders</span><br><span class=\"line\"><span class=\"literal\">--list-hwaccels</span>          show all available hardware accelerators</span><br><span class=\"line\"><span class=\"literal\">--list-demuxers</span>          show all available demuxers</span><br><span class=\"line\"><span class=\"literal\">--list-muxers</span>            show all available muxers</span><br><span class=\"line\"><span class=\"literal\">--list-parsers</span>           show all available parsers</span><br><span class=\"line\"><span class=\"literal\">--list-protocols</span>         show all available protocols</span><br><span class=\"line\"><span class=\"literal\">--list-bsfs</span>              show all available bitstream filters</span><br><span class=\"line\"><span class=\"literal\">--list-indevs</span>            show all available input devices</span><br><span class=\"line\"><span class=\"literal\">--list-outdevs</span>           show all available output devices</span><br><span class=\"line\"><span class=\"literal\">--list-filters</span>           show all available filters</span><br></pre></td></tr></table></figure>\n\n<p>其他的配置就是一些实际性的开关配置，列一些常用的配置：</p>\n<p>配置产物为静态库(.a)或者动态库(.so)</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">--enable-static         do not build static libraries [no]</span><br><span class=\"line\">--enable-shared         build shared libraries [no]</span><br></pre></td></tr></table></figure>\n\n<p>配置减少包大小</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">--enable-small           optimize for size instead of speed</span><br></pre></td></tr></table></figure>\n\n<p><code>--enable-small</code> 的配置项，其实是在config.h里声称了CONFIG_SMALL选项，然后代码内根据CONFIG_SMALL做了一些调整，比如某些string类型就被省掉了，还有一些内置生成的table, 体积也被裁减掉了，用速度换体积。比如这里：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">if</span> CONFIG_SMALL</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> CRC_TABLE_SIZE 257</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">else</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> CRC_TABLE_SIZE 1024</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">endif</span></span></span><br></pre></td></tr></table></figure>\n\n<p>配置FFmpeg协议，由于我们使用本地文件，需要再加一个： <code>--enable-protocol=file</code>，要不然解码会报协议相关错误</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"literal\">--disable-protocols</span>      disable all protocols</span><br></pre></td></tr></table></figure>\n\n<p>我们只需要在代码中使用 FFmpeg，所以直接禁用命令行工具</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"literal\">--disable-programs</span>       <span class=\"keyword\">do</span> not build command line programs</span><br><span class=\"line\"><span class=\"literal\">--disable-ffmpeg</span>         disable ffmpeg build</span><br><span class=\"line\"><span class=\"literal\">--disable-ffplay</span>         disable ffplay build</span><br><span class=\"line\"><span class=\"literal\">--disable-ffprobe</span>        disable ffprobe build</span><br></pre></td></tr></table></figure>\n\n<p>还有几个比较重要的就是，主要是</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"literal\">--disable-avdevice</span>       disable libavdevice build</span><br><span class=\"line\"><span class=\"literal\">--disable-swresample</span>     disable libswresample build</span><br><span class=\"line\"><span class=\"literal\">--disable-swscale</span>        disable libswscale build</span><br><span class=\"line\"><span class=\"literal\">--disable-postproc</span>       disable libpostproc build</span><br><span class=\"line\"><span class=\"literal\">--disable-avfilter</span>       disable libavfilter build</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"编译遇见的坑\"><a href=\"#编译遇见的坑\" class=\"headerlink\" title=\"编译遇见的坑\"></a>编译遇见的坑</h2><p><strong>1、aarch64-linux-android21-clang is unable to create an executable file.<br>C compiler test failed.</strong></p>\n<p>这个问题是困扰我最久的，按照解决方法：<br>原因 1： FFmpeg 4.2.2 版本默认使用了 clang 进行编译<br>解决：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">//1\\. 修改 configure 文件</span><br><span class=\"line\">vim configure</span><br><span class=\"line\">//2\\. 把 默认的 clang 修改为 gcc</span><br><span class=\"line\">if test &quot;$target_os&quot; = android; then</span><br><span class=\"line\">   # cc_default=&quot;clang&quot;</span><br><span class=\"line\">\t\t cc_default=&quot;gcc&quot;</span><br><span class=\"line\">fi</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>原因2，检查路径是否正确，主要是 NDK 的位置，以及不同 NDK 相关库可能存在一定的丢失。</p>\n<p>这个问题我在 macOS 上未解决，<strong>换用 CentOS 没有出现过这个编译问题</strong>。</p>\n<p><strong>2、 编译包大小一直不变</strong></p>\n<p>最开始我正常编译的时候发现怎么改配置，最后的包大小都没有发生变化，但是命令行里面各种流程又是在走，最终也有产物。这里一定要关注在执行了编译脚本之后，查看最开始的日志，看看具体是一些什么错，这里日志会刷得很快，如果包大小一直没有发生变化的话，可以执行完之后快速停止，看看是什么错。一般就是<code>C compiler test failed.</code> 或者找不到你的配置，改对即可。正常编译，会在开始后列出你的编译配置。</p>\n<p><strong>3、x86asm 相关的问题</strong></p>\n<p>编译的时候遇到一些 x86asm 的错，按照文章所说即可</p>\n","cover":null,"images":[],"content":"<p>此前项目一直使用的 FFmpeg.so 是我从其他团队项目中直接复制过来的，但原来的项目团队不再维护这个库，其中 x264 模块由于一些版权问题需要剔除，所以需要自己重新编译。在编译的过程中踩了很多坑，以及编译 congfigure 有太多的配置，如何减少整体编译出来的大小也是需要花点精力的，本文主要记录编译流程以及相关配置介绍。</p>\n<h2 id=\"编译介绍\"><a href=\"#编译介绍\" class=\"headerlink\" title=\"编译介绍\"></a>编译介绍</h2><p>自己编译主要参考<a href=\"https://github.com/Timdk857/Android-Architecture-knowledge-2-/blob/master/Android%20%E9%9F%B3%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97/Android-%E9%9F%B3%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97-(%E5%9B%9B)-%E4%B8%80%E9%94%AE%E7%BC%96%E8%AF%91-32-64-%E4%BD%8D-FFmpeg-4-2-2.md\">《一键编译32_64位FFmpeg.4.2.2》</a>，最开始的时候自己一直在 Mac M1 上编译，各种流程也是一比一复刻，但是仍然会有各种问题出现，最常见的就是：</p>\n<blockquote>\n<p>aarch64-linux-android21-clang is unable to create an executable file.<br>C compiler test failed.</p>\n</blockquote>\n<p>我反复检查了自己的 NDK 的配置，确保是正确的，文章也有提及处理方式，但是尝试下来都无效，在网上搜了一大篇解决方式，也都无效。不过我看他们很多都是用 Linux 系统进行的编译，遂改为使用 Linux 编译，再重新尝试，似乎没有那些个奇奇怪怪的错误了，也打出了最终的包，最后的 so 大小也符合要求。</p>\n<h3 id=\"编译环境\"><a href=\"#编译环境\" class=\"headerlink\" title=\"编译环境\"></a>编译环境</h3><ul>\n<li>CentOS 7</li>\n<li><a href=\"https://ffmpeg.org/releases/ffmpeg-4.2.2.tar.bz2\">ffmpeg-4.2.2</a></li>\n<li><a href=\"https://github.com/android/ndk/wiki/Unsupported-Downloads\">android-ndk-r20b-linux-x86_64.zip</a></li>\n</ul>\n<h3 id=\"编译脚本\"><a href=\"#编译脚本\" class=\"headerlink\" title=\"编译脚本\"></a>编译脚本</h3><p>这是我的一份编译脚本，我的需求是进行本地视频抽帧，所以不需要像滤镜、编码、音频相关的配置，只需要视频解码相关的配置，具体配置在下一节有讲解。</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/bin/bash</span></span><br><span class=\"line\">export NDK=.../android<span class=\"literal\">-ndk-r20b</span></span><br><span class=\"line\">TOOLCHAIN=<span class=\"variable\">$NDK</span>/toolchains/llvm/prebuilt/linux<span class=\"literal\">-x86_64</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">build_android</span></span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">./configure \\ </span><br><span class=\"line\"><span class=\"literal\">--prefix</span>=<span class=\"variable\">$PREFIX</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-neon</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-x86asm</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-hwaccels</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-gpl</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-nonfree</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-version3</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-postproc</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-bsfs</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-protocols</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-protocol</span>=file \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-indevs</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-outdevs</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-debug</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-small</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-jni</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-mediacodec</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-decoder</span>=h264_mediacodec \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-swscale</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-static</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-shared</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-filters</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-avfilter</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-encoders</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-muxers</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-demuxers</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-demuxer</span>=avi \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-demuxer</span>=flv \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-demuxer</span>=h261 \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-demuxer</span>=h263 \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-demuxer</span>=h264 \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-demuxer</span>=hevc \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-demuxer</span>=mov \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-demuxer</span>=m4v \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-decoders</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=h263 \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=h263i \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=h263p \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=h264 \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=hevc \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=flv \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=mpeg4 \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-parsers</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-parser</span>=h264 \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-parser</span>=h261 \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-parser</span>=h263 \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-parser</span>=mpeg4video \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-parser</span>=mpegvideo \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-htmlpages</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-manpages</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-podpages</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-txtpages</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-vaapi</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-v4l2-m2m</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-nvdec</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-nvenc</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-ffnvcodec</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-dxva2</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-d3d11va</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-cuvid</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-cuda-llvm</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-cuda-nvcc</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-audiotoolbox</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-amf</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-iconv</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-libxcb</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-libxcb-shm</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-libxcb-xfixes</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-libxcb-shape</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-lzma</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-sdl2</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-securetransport</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-xlib</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-zlib</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-programs</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-ffmpeg</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-ffplay</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-ffprobe</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-avdevice</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--disable-symver</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--cross-prefix</span>=<span class=\"variable\">$CROSS_PREFIX</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--target-os</span>=android \\ </span><br><span class=\"line\"><span class=\"literal\">--arch</span>=<span class=\"variable\">$ARCH</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--cpu</span>=<span class=\"variable\">$CPU</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--cc</span>=<span class=\"variable\">$CC</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--cxx</span>=<span class=\"variable\">$CXX</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--enable-cross-compile</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--sysroot</span>=<span class=\"variable\">$SYSROOT</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--extra-cflags</span>=<span class=\"string\">&quot;-Os -fpic <span class=\"variable\">$OPTIMIZE_CFLAGS</span>&quot;</span> \\ </span><br><span class=\"line\"><span class=\"literal\">--extra-ldflags</span>=<span class=\"string\">&quot;<span class=\"variable\">$ADDI_LDFLAGS</span>&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">make clean</span><br><span class=\"line\">make <span class=\"literal\">-j16</span></span><br><span class=\"line\">make install</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#arm64-v8a</span></span><br><span class=\"line\">ARCH=arm64</span><br><span class=\"line\">CPU=armv8<span class=\"literal\">-a</span></span><br><span class=\"line\">API=<span class=\"number\">21</span></span><br><span class=\"line\">CC=<span class=\"variable\">$TOOLCHAIN</span>/bin/aarch64<span class=\"literal\">-linux-android</span><span class=\"variable\">$API</span><span class=\"literal\">-clang</span></span><br><span class=\"line\">CXX=<span class=\"variable\">$TOOLCHAIN</span>/bin/aarch64<span class=\"literal\">-linux-android</span><span class=\"variable\">$API</span><span class=\"literal\">-clang</span>++</span><br><span class=\"line\">SYSROOT=<span class=\"variable\">$NDK</span>/toolchains/llvm/prebuilt/linux<span class=\"literal\">-x86_64</span>/sysroot</span><br><span class=\"line\">CROSS_PREFIX=<span class=\"variable\">$TOOLCHAIN</span>/bin/aarch64<span class=\"literal\">-linux-android-</span></span><br><span class=\"line\">PREFIX=<span class=\"variable\">$</span>(<span class=\"built_in\">pwd</span>)/android/<span class=\"variable\">$CPU</span></span><br><span class=\"line\">OPTIMIZE_CFLAGS=<span class=\"string\">&quot;-march=<span class=\"variable\">$CPU</span>&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">build_android</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#armv7-a</span></span><br><span class=\"line\">ARCH=arm</span><br><span class=\"line\">CPU=armv7<span class=\"literal\">-a</span></span><br><span class=\"line\">API=<span class=\"number\">21</span></span><br><span class=\"line\">CC=<span class=\"variable\">$TOOLCHAIN</span>/bin/armv7a<span class=\"literal\">-linux-androideabi</span><span class=\"variable\">$API</span><span class=\"literal\">-clang</span></span><br><span class=\"line\">CXX=<span class=\"variable\">$TOOLCHAIN</span>/bin/armv7a<span class=\"literal\">-linux-androideabi</span><span class=\"variable\">$API</span><span class=\"literal\">-clang</span>++</span><br><span class=\"line\">SYSROOT=<span class=\"variable\">$NDK</span>/toolchains/llvm/prebuilt/linux<span class=\"literal\">-x86_64</span>/sysroot</span><br><span class=\"line\">CROSS_PREFIX=<span class=\"variable\">$TOOLCHAIN</span>/bin/arm<span class=\"literal\">-linux-androideabi-</span></span><br><span class=\"line\">PREFIX=<span class=\"variable\">$</span>(<span class=\"built_in\">pwd</span>)/android/<span class=\"variable\">$CPU</span></span><br><span class=\"line\">OPTIMIZE_CFLAGS=<span class=\"string\">&quot;-mfloat-abi=softfp -mfpu=vfp -marm -march=<span class=\"variable\">$CPU</span> &quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">build_android</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"配置介绍\"><a href=\"#配置介绍\" class=\"headerlink\" title=\"配置介绍\"></a>配置介绍</h2><p>通过执行 <code>./configure --help</code> 能得到所有的配置选项，整个配置也非常好理解，通过 list-xxx 可以知道有哪些子选项，然后再通过 <code>--disable-xxx</code>,或者 <code>--enable-xxx</code> 进行关闭或者打开。以解码为例：</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"literal\">--disable-decoders</span>       <span class=\"comment\"># 先关闭所有的解码器</span></span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=flv     <span class=\"comment\"># 然后只打开flv、mpeg4 的支持</span></span><br><span class=\"line\"><span class=\"literal\">--enable-decoder</span>=mpeg4 </span><br></pre></td></tr></table></figure>\n<p>对于<code>--enable-decoder=xxx</code>中的xxx可以通过 <code>./configure --list-decoders</code> 进行查看，同理 <code>encoders</code> <code>demuxers</code> <code>muxers</code> 等都是类似的处理，通过 <code>--help</code> 可以通过 <code>list--xxx</code> 查看不同功能的可以支持的配置，主要有以下：</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"literal\">--list-decoders</span>          show all available decoders</span><br><span class=\"line\"><span class=\"literal\">--list-encoders</span>          show all available encoders</span><br><span class=\"line\"><span class=\"literal\">--list-hwaccels</span>          show all available hardware accelerators</span><br><span class=\"line\"><span class=\"literal\">--list-demuxers</span>          show all available demuxers</span><br><span class=\"line\"><span class=\"literal\">--list-muxers</span>            show all available muxers</span><br><span class=\"line\"><span class=\"literal\">--list-parsers</span>           show all available parsers</span><br><span class=\"line\"><span class=\"literal\">--list-protocols</span>         show all available protocols</span><br><span class=\"line\"><span class=\"literal\">--list-bsfs</span>              show all available bitstream filters</span><br><span class=\"line\"><span class=\"literal\">--list-indevs</span>            show all available input devices</span><br><span class=\"line\"><span class=\"literal\">--list-outdevs</span>           show all available output devices</span><br><span class=\"line\"><span class=\"literal\">--list-filters</span>           show all available filters</span><br></pre></td></tr></table></figure>\n\n<p>其他的配置就是一些实际性的开关配置，列一些常用的配置：</p>\n<p>配置产物为静态库(.a)或者动态库(.so)</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">--enable-static         do not build static libraries [no]</span><br><span class=\"line\">--enable-shared         build shared libraries [no]</span><br></pre></td></tr></table></figure>\n\n<p>配置减少包大小</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">--enable-small           optimize for size instead of speed</span><br></pre></td></tr></table></figure>\n\n<p><code>--enable-small</code> 的配置项，其实是在config.h里声称了CONFIG_SMALL选项，然后代码内根据CONFIG_SMALL做了一些调整，比如某些string类型就被省掉了，还有一些内置生成的table, 体积也被裁减掉了，用速度换体积。比如这里：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">if</span> CONFIG_SMALL</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> CRC_TABLE_SIZE 257</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">else</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> CRC_TABLE_SIZE 1024</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">endif</span></span></span><br></pre></td></tr></table></figure>\n\n<p>配置FFmpeg协议，由于我们使用本地文件，需要再加一个： <code>--enable-protocol=file</code>，要不然解码会报协议相关错误</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"literal\">--disable-protocols</span>      disable all protocols</span><br></pre></td></tr></table></figure>\n\n<p>我们只需要在代码中使用 FFmpeg，所以直接禁用命令行工具</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"literal\">--disable-programs</span>       <span class=\"keyword\">do</span> not build command line programs</span><br><span class=\"line\"><span class=\"literal\">--disable-ffmpeg</span>         disable ffmpeg build</span><br><span class=\"line\"><span class=\"literal\">--disable-ffplay</span>         disable ffplay build</span><br><span class=\"line\"><span class=\"literal\">--disable-ffprobe</span>        disable ffprobe build</span><br></pre></td></tr></table></figure>\n\n<p>还有几个比较重要的就是，主要是</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"literal\">--disable-avdevice</span>       disable libavdevice build</span><br><span class=\"line\"><span class=\"literal\">--disable-swresample</span>     disable libswresample build</span><br><span class=\"line\"><span class=\"literal\">--disable-swscale</span>        disable libswscale build</span><br><span class=\"line\"><span class=\"literal\">--disable-postproc</span>       disable libpostproc build</span><br><span class=\"line\"><span class=\"literal\">--disable-avfilter</span>       disable libavfilter build</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"编译遇见的坑\"><a href=\"#编译遇见的坑\" class=\"headerlink\" title=\"编译遇见的坑\"></a>编译遇见的坑</h2><p><strong>1、aarch64-linux-android21-clang is unable to create an executable file.<br>C compiler test failed.</strong></p>\n<p>这个问题是困扰我最久的，按照解决方法：<br>原因 1： FFmpeg 4.2.2 版本默认使用了 clang 进行编译<br>解决：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">//1\\. 修改 configure 文件</span><br><span class=\"line\">vim configure</span><br><span class=\"line\">//2\\. 把 默认的 clang 修改为 gcc</span><br><span class=\"line\">if test &quot;$target_os&quot; = android; then</span><br><span class=\"line\">   # cc_default=&quot;clang&quot;</span><br><span class=\"line\">\t\t cc_default=&quot;gcc&quot;</span><br><span class=\"line\">fi</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>原因2，检查路径是否正确，主要是 NDK 的位置，以及不同 NDK 相关库可能存在一定的丢失。</p>\n<p>这个问题我在 macOS 上未解决，<strong>换用 CentOS 没有出现过这个编译问题</strong>。</p>\n<p><strong>2、 编译包大小一直不变</strong></p>\n<p>最开始我正常编译的时候发现怎么改配置，最后的包大小都没有发生变化，但是命令行里面各种流程又是在走，最终也有产物。这里一定要关注在执行了编译脚本之后，查看最开始的日志，看看具体是一些什么错，这里日志会刷得很快，如果包大小一直没有发生变化的话，可以执行完之后快速停止，看看是什么错。一般就是<code>C compiler test failed.</code> 或者找不到你的配置，改对即可。正常编译，会在开始后列出你的编译配置。</p>\n<p><strong>3、x86asm 相关的问题</strong></p>\n<p>编译的时候遇到一些 x86asm 的错，按照文章所说即可</p>\n","categories":[],"tags":[{"name":"FFmpeg","slug":"FFmpeg","api":"api/tags/FFmpeg.json"}],"api":"api/posts/2023/01/09/FFmpeg-so-编译整理.json"},{"title":"FFmpeg之AVFrame转Android Bitmap","slug":"FFmpeg之AVFrame转Android-Bitmap","date":"2022-05-22T13:03:00.000Z","updated":"2025-05-20T11:46:57.000Z","comments":true,"url":"2022/05/22/FFmpeg之AVFrame转Android-Bitmap/","excerpt":"<p>此前很多工作都设计到使用 FFmpeg 对视频帧进行获取，在 FFmpeg 解码视频文件获取到帧数据结构是 <code>AVFrame</code>, 对于应用层我们没有办法直接拿到进行数据处理，需要转换为 Android 平台特有的处理结构。而我是需要对应的帧图片数据，那么在 Android 侧需要将其转化为 <code>Bitmap</code> ,之前整理的过程中发现了这篇<a href=\"https://segmentfault.com/a/1190000016674715?utm_source=sf-similar-article\">《Android音视频开发】从AVFrame到MediaFrame数组(二)》</a>博客文章 ，觉得写得很不错，非常精简，适合我的需求，于是对齐进行整理，并标注一下自己在过程中遇到的一些坑点。</p>\n<h2 id=\"Native层创建Bitmap\"><a href=\"#Native层创建Bitmap\" class=\"headerlink\" title=\"Native层创建Bitmap\"></a>Native层创建Bitmap</h2><p><code>Bitmap</code> 是对 <a href=\"https://docs.microsoft.com/en-us/dotnet/api/skiasharp.skbitmap?view=skiasharp-2.80.2\">SkBitmap</a> 的包装。具体说来， Bitmap 的实现包括 Java 层和 JNI 层，JNI 层依赖 Skia，<code>SkBitmap</code> 本质上可简单理解为内存中的一个字节数组</p>\n<p>想要生成 <code>Bitmap</code>,  我们首先需要构造一个 <code>Bitmap</code> 对象，Java层有很多种方式可以生成Bitmap对象，最简单的方式如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">Bitmap.createBitmap(width,height,<span class=\"keyword\">new</span> <span class=\"title class_\">Bitmap</span>.Config.ARGB_8888)</span><br></pre></td></tr></table></figure>\n\n<p>由于整个 <code>FFmpeg</code>的操作在 JNI 侧进行，对应的操作需要使用 <code>JNIEnv</code>  进行相关的调用，主要逻辑如下：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">jobject <span class=\"title\">create_bitmap</span><span class=\"params\">(JNIEnv *env, <span class=\"type\">int</span> width, <span class=\"type\">int</span> height)</span> </span>&#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 找到 Bitmap.class 和 该类中的 createBitmap 方法</span></span><br><span class=\"line\">    jclass clz_bitmap = env-&gt;<span class=\"built_in\">FindClass</span>(<span class=\"string\">&quot;android/graphics/Bitmap&quot;</span>);</span><br><span class=\"line\">    jmethodID mtd_bitmap = env-&gt;<span class=\"built_in\">GetStaticMethodID</span>(</span><br><span class=\"line\">            clz_bitmap, <span class=\"string\">&quot;createBitmap&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;(IILandroid/graphics/Bitmap$Config;)Landroid/graphics/Bitmap;&quot;</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 配置 Bitmap</span></span><br><span class=\"line\">    jstring str_config = env-&gt;<span class=\"built_in\">NewStringUTF</span>(<span class=\"string\">&quot;ARGB_8888&quot;</span>);</span><br><span class=\"line\">    jclass clz_config = env-&gt;<span class=\"built_in\">FindClass</span>(<span class=\"string\">&quot;android/graphics/Bitmap$Config&quot;</span>);</span><br><span class=\"line\">    jmethodID mtd_config = env-&gt;<span class=\"built_in\">GetStaticMethodID</span>(</span><br><span class=\"line\">            clz_config, <span class=\"string\">&quot;valueOf&quot;</span>, <span class=\"string\">&quot;(Ljava/lang/String;)Landroid/graphics/Bitmap$Config;&quot;</span>);</span><br><span class=\"line\">    jobject obj_config = env-&gt;<span class=\"built_in\">CallStaticObjectMethod</span>(clz_config, mtd_config, str_config);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 创建 Bitmap 对象</span></span><br><span class=\"line\">    jobject bitmap = env-&gt;<span class=\"built_in\">CallStaticObjectMethod</span>(</span><br><span class=\"line\">            clz_bitmap, mtd_bitmap, width, height, obj_config);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> bitmap;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"获取Bitmap像素数据地址，并锁定\"><a href=\"#获取Bitmap像素数据地址，并锁定\" class=\"headerlink\" title=\"获取Bitmap像素数据地址，并锁定\"></a>获取Bitmap像素数据地址，并锁定</h2><figure class=\"highlight cpp\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">void</span> *addr_pixels;</span><br><span class=\"line\"><span class=\"built_in\">AndroidBitmap_lockPixels</span>(env, bitmap, &amp;addr_pixels);</span><br></pre></td></tr></table></figure>\n\n<p>解释一下这两句话：</p>\n<blockquote>\n<p>第一句的作用声明并定义一个指向任意类型的指针变量，名称是addr_pixels。我们定义它的目的，是让它指向bitmap像素数据(即:<br>addr_pixels的值为bitmap像素数据的地址)。注意哦，这时候，addr_pixels的值是一个随机的值(假定此时为：0x01)，由系统分配，它还不指向bitmap像素数据。<br>第二句话的作用就是将bitmap的像素数据地址赋值给addr_pixels，此时它的值被修改(假定为：0x002)。并且锁定该地址，保证不会被移动。【注：地址不会被移动这里我也不太懂什么意思，有兴趣的可以去查看该方法的API文档】<br>【注：】此时的bitmap由像素数据的地址，但是该地址内还没有任何像素数据哦，或者说它的像素数据为\\0</p>\n</blockquote>\n<p>到这里，我们已经有了源像素数据在AVFrame中，有了目的像素数据地址addr_pixels，那么接下来的任务就是将AVFrame中的像素数据写入到addr_pixels指向的那片内存中去。</p>\n<h2 id=\"向Bitmap中写入像素数据\"><a href=\"#向Bitmap中写入像素数据\" class=\"headerlink\" title=\"向Bitmap中写入像素数据\"></a>向Bitmap中写入像素数据</h2><p>这里要说一下，我们获取到的AVFrame的像素格式通常是YUV格式的，而Bitmap的像素格式通常是RGB格式的。因此我们需要将YUV格式的像素数据转换成RGB格式进行存储。而RGB的存储空间Bitmap不是已经给我门提供好了吗？嘿嘿，直接用就OK了，那现在问题就是YUV如何转换成RGB呢？<br>关于YUV和RGB之间的转换，我知道的有三种方式：</p>\n<ul>\n<li>通过公式换算</li>\n<li>FFmpeg提供的libswscale</li>\n<li>Google提供的libyuv<br>这里我们选择libyuv因为它的性能好、使用简单。</li>\n</ul>\n<p>说它使用简单，到底有多简单，嘿，一个函数就够了！！</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"code\"><pre><span class=\"line\">libyuv::<span class=\"built_in\">I420ToABGR</span>(frame-&gt;data[<span class=\"number\">0</span>], frame-&gt;linesize[<span class=\"number\">0</span>], <span class=\"comment\">// Y</span></span><br><span class=\"line\">                   frame-&gt;data[<span class=\"number\">1</span>], frame-&gt;linesize[<span class=\"number\">1</span>], <span class=\"comment\">// U</span></span><br><span class=\"line\">                   frame-&gt;data[<span class=\"number\">2</span>], frame-&gt;linesize[<span class=\"number\">2</span>], <span class=\"comment\">// V</span></span><br><span class=\"line\">                   (<span class=\"type\">uint8_t</span> *) addr_pixels, linesize,  <span class=\"comment\">// RGBA</span></span><br><span class=\"line\">                   frame-&gt;width, frame-&gt;height);</span><br></pre></td></tr></table></figure>\n\n<p>解释一下这个函数：</p>\n<ul>\n<li>I420ToABGR: I420表示的是YUV420P格式，ABGR表示的RGBA格式(execuse me?? 是的，你没看错，Google说RGBA格式的数据在底层的存储方式是ABGR，顺序反过来，看下libyuv源码的函数注释就知道了)</li>\n<li>frame-&gt;data&amp;linesize: 这些个参数表示的是源YUV数据，上面有标注</li>\n<li>(uint8_t *) addr_pixels: 嘿，这个就是说往这块空间里写入像素数据啦</li>\n<li>linesize: 这个表示的是该图片一行数据的字节大小，Bitmap按照RBGA格式存储，也就是说一个像素是4个字节，那么一行共有：frame-&gt;width 个像素，所以：<br>linesize &#x3D; frame-&gt; width * 4</li>\n</ul>\n<p>【注：】关于这一小块功能的实现，可能其他地方你会看到这样的写法，他们用了如下接口：</p>\n<p>&#x2F;&#x2F; 思路</p>\n<blockquote>\n<p>是：新建一个AVFrame(RGB格式)，通过av_image_fill_arrays来实现AVFrame(RGB)中像素数据和Bitmap像素数据的关联，也就是让AVFrame(RGB)像素数据指针等于addr_pixels<br>pRGBFrame &#x3D; av_frame_alloc() av_image_get_buffer_size()<br>av_image_fill_arrays() &#x2F;*<br>我也是写到这里的时候，才想到这个问题，为什么要这样用呢，直接使用addr_pixels不是也一样可以么？<br>不过大家都这么用，应该是有它不可替代的使用场景的。因此这里也说一下av_image_fill_arrays这个函数。<br>*&#x2F;</p>\n<p>&#x2F;&#x2F; TODO: 解释下这个函数的作用 av_image_fill_arrays(dst_data, dst_linesize,<br>src_data, pix_fmt, width, height, align); 它的作用就是</p>\n<ol>\n<li>根据src_data，设置dst_data，事实上根据现象或者自己去调试，可以发现dst_data的值就是src_data的值(我印象中好像值是相同的，这会我忘了，后面我再验证下)</li>\n<li>根据pix_fmt, width, height设置linesize的值，其实linesize的计算就和我上面给出的那个公式是一样子的值</li>\n</ol>\n</blockquote>\n<p>OK, 函数执行完毕，我们Bitmap就有了像素数据，下面就是把Bitmap上传给Java层</p>\n<h2 id=\"Native回调Java接口\"><a href=\"#Native回调Java接口\" class=\"headerlink\" title=\"Native回调Java接口\"></a>Native回调Java接口</h2><p>说下Java层</p>\n<p>有一个MainActivity.java用于界面的显示<br>有一个JNIHelper.java用于Java层和Native层的沟通</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">JNIHelper</span> &#123;</span><br><span class=\"line\">   <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">onReceived</span><span class=\"params\">(Bitmap bitmap)</span>&#123;</span><br><span class=\"line\">       <span class=\"comment\">// <span class=\"doctag\">TODO:</span> Java层接收到Bitmap后，可以开始搞事情了</span></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>Native层的回调代码如下：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"code\"><pre><span class=\"line\">jclass clz = env-&gt;<span class=\"built_in\">FindClass</span>(<span class=\"string\">&quot;me/oogh/xplayer/JNIHelper&quot;</span>);</span><br><span class=\"line\">jmethodID method = env-&gt;<span class=\"built_in\">GetMethodID</span>(clz, <span class=\"string\">&quot;onReceived&quot;</span>, <span class=\"string\">&quot;(Landroid/graphics/Bitmap;)V&quot;</span>);</span><br><span class=\"line\">env-&gt;<span class=\"built_in\">CallVoidMethod</span>(obj, method, bitmap);</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"AndroidBitmap-lockPixels-方法\"><a href=\"#AndroidBitmap-lockPixels-方法\" class=\"headerlink\" title=\"AndroidBitmap_lockPixels 方法\"></a>AndroidBitmap_lockPixels 方法</h2><p>以上就是整个文章的内容，使用起来也是 no problem!  但使用过程中遇到的问题就是内存回收的问题，最开始使用的时候并没有过多关注JNI层 <code>AndroidBitmap_lockPixels</code>这个方法，以至于后来我在处理Bitmap内存回收上遇到了一些问题。 <code>AndroidBitmap_lockPixels</code> 与之对应还有一个   <code>AndroidBitmap_unlockPixels</code></p>\n<p><code>AndroidBitmap_lockPixels</code> “函数作用锁定了像素缓存以确保像素的内存不会被移动”，这句话看起来好像挺难理解，但是我们在 Java层面有与之类似的操作，那就是 <code>SurfaceHolder.lockCanvas()</code>，还记得我们在绘制的过程中需要先使用 <code>lockCanvas</code> 锁定画布，返回的画布对象<code>Canvas</code>然后使用 <code>unlockCanvasAndPost(Canvas canvas)</code> 结束锁定画布，并提交改变。<code>AndroidBitmap_lockPixels</code> 与  <code>AndroidBitmap_unlockPixels</code>做的是类似的事情，都是锁住一块内存区域，保证其安全。</p>\n<p>回到上面说的内存回收的问题，由于自己使用失误，流程大概是这样：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">AndroidBitmap_lockPixels</span>(env, bitmap, &amp;addr_pixels);</span><br><span class=\"line\"><span class=\"comment\">//在两者之间，将生成好的 Bitmap Obj 回调到Java层</span></span><br><span class=\"line\"><span class=\"built_in\">AndroidBitmap_unlockPixels</span>(env, bitmap);</span><br></pre></td></tr></table></figure>\n\n<p>然后在Java层有这样的逻辑：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">onReceived</span><span class=\"params\">(Bitmap bitmap)</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//……一些业务逻辑</span></span><br><span class=\"line\">    <span class=\"comment\">//我们习惯性对bitmap使用recycle对其数据进行回收……</span></span><br><span class=\"line\">    bitmap.recycle()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>但是我发现使用了 <code>bitmap.recycle()</code>与不使用，内存中 Native区域仍然占了一大部分，后来在<code>AndroidBitmap_lockPixels</code>的注释才发现不对的地方：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Given a java bitmap object, attempt to lock the pixel address.</span></span><br><span class=\"line\"><span class=\"comment\"> * Locking will ensure that the memory for the pixels will not move</span></span><br><span class=\"line\"><span class=\"comment\"> * until the unlockPixels call, and ensure that, if the pixels had been</span></span><br><span class=\"line\"><span class=\"comment\"> * previously purged, they will have been restored.</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * If this call succeeds, it must be balanced by a call to</span></span><br><span class=\"line\"><span class=\"comment\"> * AndroidBitmap_unlockPixels, after which time the address of the pixels should</span></span><br><span class=\"line\"><span class=\"comment\"> * no longer be used.</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * If this succeeds, *addrPtr will be set to the pixel address. If the call</span></span><br><span class=\"line\"><span class=\"comment\"> * fails, addrPtr will be ignored.</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">AndroidBitmap_lockPixels</span><span class=\"params\">(JNIEnv* env, jobject jbitmap, <span class=\"type\">void</span>** addrPtr)</span></span>;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>其中：</p>\n<blockquote>\n<p><strong>if the pixels had been previously purged, they will have been restored.</strong></p>\n</blockquote>\n<p>也就是说在<code>AndroidBitmap_unlockPixels</code> 调用之前，如果像素数据被销毁了，他们会被恢复！至于为什么会被恢复，这个就需要之后再进行研究了。</p>\n<p>后来对逻辑进行更改，将 Bitmap.recycle()的逻辑移动到 AndroidBitmap_unlockPixels之后。</p>\n","cover":null,"images":[],"content":"<p>此前很多工作都设计到使用 FFmpeg 对视频帧进行获取，在 FFmpeg 解码视频文件获取到帧数据结构是 <code>AVFrame</code>, 对于应用层我们没有办法直接拿到进行数据处理，需要转换为 Android 平台特有的处理结构。而我是需要对应的帧图片数据，那么在 Android 侧需要将其转化为 <code>Bitmap</code> ,之前整理的过程中发现了这篇<a href=\"https://segmentfault.com/a/1190000016674715?utm_source=sf-similar-article\">《Android音视频开发】从AVFrame到MediaFrame数组(二)》</a>博客文章 ，觉得写得很不错，非常精简，适合我的需求，于是对齐进行整理，并标注一下自己在过程中遇到的一些坑点。</p>\n<h2 id=\"Native层创建Bitmap\"><a href=\"#Native层创建Bitmap\" class=\"headerlink\" title=\"Native层创建Bitmap\"></a>Native层创建Bitmap</h2><p><code>Bitmap</code> 是对 <a href=\"https://docs.microsoft.com/en-us/dotnet/api/skiasharp.skbitmap?view=skiasharp-2.80.2\">SkBitmap</a> 的包装。具体说来， Bitmap 的实现包括 Java 层和 JNI 层，JNI 层依赖 Skia，<code>SkBitmap</code> 本质上可简单理解为内存中的一个字节数组</p>\n<p>想要生成 <code>Bitmap</code>,  我们首先需要构造一个 <code>Bitmap</code> 对象，Java层有很多种方式可以生成Bitmap对象，最简单的方式如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">Bitmap.createBitmap(width,height,<span class=\"keyword\">new</span> <span class=\"title class_\">Bitmap</span>.Config.ARGB_8888)</span><br></pre></td></tr></table></figure>\n\n<p>由于整个 <code>FFmpeg</code>的操作在 JNI 侧进行，对应的操作需要使用 <code>JNIEnv</code>  进行相关的调用，主要逻辑如下：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">jobject <span class=\"title\">create_bitmap</span><span class=\"params\">(JNIEnv *env, <span class=\"type\">int</span> width, <span class=\"type\">int</span> height)</span> </span>&#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 找到 Bitmap.class 和 该类中的 createBitmap 方法</span></span><br><span class=\"line\">    jclass clz_bitmap = env-&gt;<span class=\"built_in\">FindClass</span>(<span class=\"string\">&quot;android/graphics/Bitmap&quot;</span>);</span><br><span class=\"line\">    jmethodID mtd_bitmap = env-&gt;<span class=\"built_in\">GetStaticMethodID</span>(</span><br><span class=\"line\">            clz_bitmap, <span class=\"string\">&quot;createBitmap&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;(IILandroid/graphics/Bitmap$Config;)Landroid/graphics/Bitmap;&quot;</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 配置 Bitmap</span></span><br><span class=\"line\">    jstring str_config = env-&gt;<span class=\"built_in\">NewStringUTF</span>(<span class=\"string\">&quot;ARGB_8888&quot;</span>);</span><br><span class=\"line\">    jclass clz_config = env-&gt;<span class=\"built_in\">FindClass</span>(<span class=\"string\">&quot;android/graphics/Bitmap$Config&quot;</span>);</span><br><span class=\"line\">    jmethodID mtd_config = env-&gt;<span class=\"built_in\">GetStaticMethodID</span>(</span><br><span class=\"line\">            clz_config, <span class=\"string\">&quot;valueOf&quot;</span>, <span class=\"string\">&quot;(Ljava/lang/String;)Landroid/graphics/Bitmap$Config;&quot;</span>);</span><br><span class=\"line\">    jobject obj_config = env-&gt;<span class=\"built_in\">CallStaticObjectMethod</span>(clz_config, mtd_config, str_config);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 创建 Bitmap 对象</span></span><br><span class=\"line\">    jobject bitmap = env-&gt;<span class=\"built_in\">CallStaticObjectMethod</span>(</span><br><span class=\"line\">            clz_bitmap, mtd_bitmap, width, height, obj_config);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> bitmap;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"获取Bitmap像素数据地址，并锁定\"><a href=\"#获取Bitmap像素数据地址，并锁定\" class=\"headerlink\" title=\"获取Bitmap像素数据地址，并锁定\"></a>获取Bitmap像素数据地址，并锁定</h2><figure class=\"highlight cpp\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">void</span> *addr_pixels;</span><br><span class=\"line\"><span class=\"built_in\">AndroidBitmap_lockPixels</span>(env, bitmap, &amp;addr_pixels);</span><br></pre></td></tr></table></figure>\n\n<p>解释一下这两句话：</p>\n<blockquote>\n<p>第一句的作用声明并定义一个指向任意类型的指针变量，名称是addr_pixels。我们定义它的目的，是让它指向bitmap像素数据(即:<br>addr_pixels的值为bitmap像素数据的地址)。注意哦，这时候，addr_pixels的值是一个随机的值(假定此时为：0x01)，由系统分配，它还不指向bitmap像素数据。<br>第二句话的作用就是将bitmap的像素数据地址赋值给addr_pixels，此时它的值被修改(假定为：0x002)。并且锁定该地址，保证不会被移动。【注：地址不会被移动这里我也不太懂什么意思，有兴趣的可以去查看该方法的API文档】<br>【注：】此时的bitmap由像素数据的地址，但是该地址内还没有任何像素数据哦，或者说它的像素数据为\\0</p>\n</blockquote>\n<p>到这里，我们已经有了源像素数据在AVFrame中，有了目的像素数据地址addr_pixels，那么接下来的任务就是将AVFrame中的像素数据写入到addr_pixels指向的那片内存中去。</p>\n<h2 id=\"向Bitmap中写入像素数据\"><a href=\"#向Bitmap中写入像素数据\" class=\"headerlink\" title=\"向Bitmap中写入像素数据\"></a>向Bitmap中写入像素数据</h2><p>这里要说一下，我们获取到的AVFrame的像素格式通常是YUV格式的，而Bitmap的像素格式通常是RGB格式的。因此我们需要将YUV格式的像素数据转换成RGB格式进行存储。而RGB的存储空间Bitmap不是已经给我门提供好了吗？嘿嘿，直接用就OK了，那现在问题就是YUV如何转换成RGB呢？<br>关于YUV和RGB之间的转换，我知道的有三种方式：</p>\n<ul>\n<li>通过公式换算</li>\n<li>FFmpeg提供的libswscale</li>\n<li>Google提供的libyuv<br>这里我们选择libyuv因为它的性能好、使用简单。</li>\n</ul>\n<p>说它使用简单，到底有多简单，嘿，一个函数就够了！！</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"code\"><pre><span class=\"line\">libyuv::<span class=\"built_in\">I420ToABGR</span>(frame-&gt;data[<span class=\"number\">0</span>], frame-&gt;linesize[<span class=\"number\">0</span>], <span class=\"comment\">// Y</span></span><br><span class=\"line\">                   frame-&gt;data[<span class=\"number\">1</span>], frame-&gt;linesize[<span class=\"number\">1</span>], <span class=\"comment\">// U</span></span><br><span class=\"line\">                   frame-&gt;data[<span class=\"number\">2</span>], frame-&gt;linesize[<span class=\"number\">2</span>], <span class=\"comment\">// V</span></span><br><span class=\"line\">                   (<span class=\"type\">uint8_t</span> *) addr_pixels, linesize,  <span class=\"comment\">// RGBA</span></span><br><span class=\"line\">                   frame-&gt;width, frame-&gt;height);</span><br></pre></td></tr></table></figure>\n\n<p>解释一下这个函数：</p>\n<ul>\n<li>I420ToABGR: I420表示的是YUV420P格式，ABGR表示的RGBA格式(execuse me?? 是的，你没看错，Google说RGBA格式的数据在底层的存储方式是ABGR，顺序反过来，看下libyuv源码的函数注释就知道了)</li>\n<li>frame-&gt;data&amp;linesize: 这些个参数表示的是源YUV数据，上面有标注</li>\n<li>(uint8_t *) addr_pixels: 嘿，这个就是说往这块空间里写入像素数据啦</li>\n<li>linesize: 这个表示的是该图片一行数据的字节大小，Bitmap按照RBGA格式存储，也就是说一个像素是4个字节，那么一行共有：frame-&gt;width 个像素，所以：<br>linesize &#x3D; frame-&gt; width * 4</li>\n</ul>\n<p>【注：】关于这一小块功能的实现，可能其他地方你会看到这样的写法，他们用了如下接口：</p>\n<p>&#x2F;&#x2F; 思路</p>\n<blockquote>\n<p>是：新建一个AVFrame(RGB格式)，通过av_image_fill_arrays来实现AVFrame(RGB)中像素数据和Bitmap像素数据的关联，也就是让AVFrame(RGB)像素数据指针等于addr_pixels<br>pRGBFrame &#x3D; av_frame_alloc() av_image_get_buffer_size()<br>av_image_fill_arrays() &#x2F;*<br>我也是写到这里的时候，才想到这个问题，为什么要这样用呢，直接使用addr_pixels不是也一样可以么？<br>不过大家都这么用，应该是有它不可替代的使用场景的。因此这里也说一下av_image_fill_arrays这个函数。<br>*&#x2F;</p>\n<p>&#x2F;&#x2F; TODO: 解释下这个函数的作用 av_image_fill_arrays(dst_data, dst_linesize,<br>src_data, pix_fmt, width, height, align); 它的作用就是</p>\n<ol>\n<li>根据src_data，设置dst_data，事实上根据现象或者自己去调试，可以发现dst_data的值就是src_data的值(我印象中好像值是相同的，这会我忘了，后面我再验证下)</li>\n<li>根据pix_fmt, width, height设置linesize的值，其实linesize的计算就和我上面给出的那个公式是一样子的值</li>\n</ol>\n</blockquote>\n<p>OK, 函数执行完毕，我们Bitmap就有了像素数据，下面就是把Bitmap上传给Java层</p>\n<h2 id=\"Native回调Java接口\"><a href=\"#Native回调Java接口\" class=\"headerlink\" title=\"Native回调Java接口\"></a>Native回调Java接口</h2><p>说下Java层</p>\n<p>有一个MainActivity.java用于界面的显示<br>有一个JNIHelper.java用于Java层和Native层的沟通</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">JNIHelper</span> &#123;</span><br><span class=\"line\">   <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">onReceived</span><span class=\"params\">(Bitmap bitmap)</span>&#123;</span><br><span class=\"line\">       <span class=\"comment\">// <span class=\"doctag\">TODO:</span> Java层接收到Bitmap后，可以开始搞事情了</span></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>Native层的回调代码如下：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"code\"><pre><span class=\"line\">jclass clz = env-&gt;<span class=\"built_in\">FindClass</span>(<span class=\"string\">&quot;me/oogh/xplayer/JNIHelper&quot;</span>);</span><br><span class=\"line\">jmethodID method = env-&gt;<span class=\"built_in\">GetMethodID</span>(clz, <span class=\"string\">&quot;onReceived&quot;</span>, <span class=\"string\">&quot;(Landroid/graphics/Bitmap;)V&quot;</span>);</span><br><span class=\"line\">env-&gt;<span class=\"built_in\">CallVoidMethod</span>(obj, method, bitmap);</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"AndroidBitmap-lockPixels-方法\"><a href=\"#AndroidBitmap-lockPixels-方法\" class=\"headerlink\" title=\"AndroidBitmap_lockPixels 方法\"></a>AndroidBitmap_lockPixels 方法</h2><p>以上就是整个文章的内容，使用起来也是 no problem!  但使用过程中遇到的问题就是内存回收的问题，最开始使用的时候并没有过多关注JNI层 <code>AndroidBitmap_lockPixels</code>这个方法，以至于后来我在处理Bitmap内存回收上遇到了一些问题。 <code>AndroidBitmap_lockPixels</code> 与之对应还有一个   <code>AndroidBitmap_unlockPixels</code></p>\n<p><code>AndroidBitmap_lockPixels</code> “函数作用锁定了像素缓存以确保像素的内存不会被移动”，这句话看起来好像挺难理解，但是我们在 Java层面有与之类似的操作，那就是 <code>SurfaceHolder.lockCanvas()</code>，还记得我们在绘制的过程中需要先使用 <code>lockCanvas</code> 锁定画布，返回的画布对象<code>Canvas</code>然后使用 <code>unlockCanvasAndPost(Canvas canvas)</code> 结束锁定画布，并提交改变。<code>AndroidBitmap_lockPixels</code> 与  <code>AndroidBitmap_unlockPixels</code>做的是类似的事情，都是锁住一块内存区域，保证其安全。</p>\n<p>回到上面说的内存回收的问题，由于自己使用失误，流程大概是这样：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">AndroidBitmap_lockPixels</span>(env, bitmap, &amp;addr_pixels);</span><br><span class=\"line\"><span class=\"comment\">//在两者之间，将生成好的 Bitmap Obj 回调到Java层</span></span><br><span class=\"line\"><span class=\"built_in\">AndroidBitmap_unlockPixels</span>(env, bitmap);</span><br></pre></td></tr></table></figure>\n\n<p>然后在Java层有这样的逻辑：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">onReceived</span><span class=\"params\">(Bitmap bitmap)</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//……一些业务逻辑</span></span><br><span class=\"line\">    <span class=\"comment\">//我们习惯性对bitmap使用recycle对其数据进行回收……</span></span><br><span class=\"line\">    bitmap.recycle()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>但是我发现使用了 <code>bitmap.recycle()</code>与不使用，内存中 Native区域仍然占了一大部分，后来在<code>AndroidBitmap_lockPixels</code>的注释才发现不对的地方：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Given a java bitmap object, attempt to lock the pixel address.</span></span><br><span class=\"line\"><span class=\"comment\"> * Locking will ensure that the memory for the pixels will not move</span></span><br><span class=\"line\"><span class=\"comment\"> * until the unlockPixels call, and ensure that, if the pixels had been</span></span><br><span class=\"line\"><span class=\"comment\"> * previously purged, they will have been restored.</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * If this call succeeds, it must be balanced by a call to</span></span><br><span class=\"line\"><span class=\"comment\"> * AndroidBitmap_unlockPixels, after which time the address of the pixels should</span></span><br><span class=\"line\"><span class=\"comment\"> * no longer be used.</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * If this succeeds, *addrPtr will be set to the pixel address. If the call</span></span><br><span class=\"line\"><span class=\"comment\"> * fails, addrPtr will be ignored.</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">AndroidBitmap_lockPixels</span><span class=\"params\">(JNIEnv* env, jobject jbitmap, <span class=\"type\">void</span>** addrPtr)</span></span>;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>其中：</p>\n<blockquote>\n<p><strong>if the pixels had been previously purged, they will have been restored.</strong></p>\n</blockquote>\n<p>也就是说在<code>AndroidBitmap_unlockPixels</code> 调用之前，如果像素数据被销毁了，他们会被恢复！至于为什么会被恢复，这个就需要之后再进行研究了。</p>\n<p>后来对逻辑进行更改，将 Bitmap.recycle()的逻辑移动到 AndroidBitmap_unlockPixels之后。</p>\n","categories":[{"name":"技术文章","slug":"technology","api":"api/categories/technology.json"}],"tags":[{"name":"FFmpeg","slug":"FFmpeg","api":"api/tags/FFmpeg.json"}],"api":"api/posts/2022/05/22/FFmpeg之AVFrame转Android-Bitmap.json"},{"title":"Android 视频抽帧","slug":"Android-视频抽帧相关","date":"2022-02-22T08:11:00.000Z","updated":"2025-05-20T11:46:57.000Z","comments":true,"url":"2022/02/22/Android-视频抽帧相关/","excerpt":"<p>要对移动端的抽帧，对于 iOS 来说，有 <a href=\"https://developer.apple.com/documentation/avfoundation\">AVFoundation</a> 这样一个神奇的库，开箱即用，已经支持了抽帧并且效率非常的高。而 Android 就不那么乐观了，Android 自带的 <code>MediaMetadataRetriever</code> 也能实现抽帧并将帧数据转化为 Bitmap，但效率非常低，平均抽取一帧需要 200ms-300ms，这当然满足不了我们的需求。无独有偶，Android 还提供了另一个类 <code>MediaCodec</code>-用于对音视频进行编解码的类，它通过访问底层的 codec 来实现编解码的功能，我们能对解码的数据进行定制化处理，本文也主要讲解利用 MediaCodec 进行抽帧。</p>\n<h2 id=\"一、MediaCodec\"><a href=\"#一、MediaCodec\" class=\"headerlink\" title=\"一、MediaCodec\"></a>一、MediaCodec</h2><p>为什么选择 MediaCodec? 项目的前期做了比较多的调研，在 Android 平台上除了 <code>MediaCodec</code> 还可以实现抽帧的方案有：<code>MediaMetadataRetriever</code>、<code>OpenCV</code>、<code>FFmpeg</code>，对于前两者实现效率非常的低，获取成本也比较大，对于 <code>FFmpeg</code>方案有进行了一定的尝试，ffmpeg是软解码抽帧(当然ffmpeg也可以 ffmpeg+mediaCodec 进行硬解码)，在设置 <code>AVCodecContext-&gt;thread_count=8</code> 速度提升了很多个档次，但对于 CPU 的使用率非常的高，消耗资源比较严重，不利于手机的流畅度，这里不再赘述。</p>\n<img src=\"https://cdn.julis.wang/blog/img/59036b70b7b44ccbad6b0b5c75445820.png\">\n\n<p>如上图所示 ffmpeg 软解 CPU 的使用率，维持在80%左右。</p>\n<p>MediaCodec 实现抽帧主要是参考 bigflake 网站提供的抽帧 Demo:<br><a href=\"https://bigflake.com/mediacodec/ExtractMpegFramesTest_egl14.java.txt\">ExtractMpegFramesTest</a></p>\n<p>主要方案流程如下图所示：</p>\n<img src=\"https://cdn.julis.wang/blog/img/b256cc7c59104dfa992e7672be571009.png\">\n<p>方案使用 <code>MediaExtractor</code> 获取 Codec-specific Data(对于H.264来说，”csd-0”和”csd-1”分别对应sps和pps；对于AAC来说，”csd-0”对应ADTS)发送给 <code>MediaCodec</code> 进行解码，将解码后的数据存放在 <code>Surface</code>，由于不需要将解码后的帧进行播放展示，我们进行离屏渲染(Pbuffer)，通过 <code>glReadPixels()</code> 将 GPU 渲染完存在显存数据，回传内存。获取到对应帧 Buffer 数据之后，再利用<code>Bitmap.copyPixelsFromBuffer</code> 创建 Android 平台 Bitmap 对象。</p>\n<p>但整个方案尝试下来之后发现：使用 <code>glReadPixels</code> 将显存数据回传，以及保存 Bitmap 是比较耗时以及消耗内存的操作。</p>\n<p>那么我们可以将数据不进行回传也不保存为 Bitmap，而直接使用 GPU 上的数据进行识别么？</p>\n<h2 id=\"二、GPU-Buffer-生成流程\"><a href=\"#二、GPU-Buffer-生成流程\" class=\"headerlink\" title=\"二、GPU Buffer 生成流程\"></a>二、GPU Buffer 生成流程</h2><p>在创建GPU Buffer之前我们需要简单介绍一下 <code>SurfaceTexture</code>，SurfaceTexture 是离屏渲染,内部包含了一个BufferQueue，可以把 Surface 生成的图像流，转换为纹理，供进一步加工使用。那么 <code>SurfaceTexture</code> 与前面的 MediaCodec 结合起来</p>\n<p>我们的目的是为了将 GPU 上的图片 buffer 传递给算法侧进行识别，来自 SurfaceTexture 只支持外部 GLES 纹理<code>GL_TEXTURE_EXTERNAL_OES</code>，而算法一般都是基于 <code>OpenGL</code>使用 <code>GL_TEXTURE_2D</code> , 所以需要客户端这边做一个转换工作。</p>\n<p>外部纹理 <code>GL_TEXTURE_EXTERNAL_OES</code> 的主要优势是它们能够直接从 BufferQueue 数据进行渲染。</p>\n<p>整体流程如下图所示：<br><img src=\"https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f9b96bb960304a46867fe7d65a27f540~tplv-k3u1fbpfcp-zoom-crop-mark:3024:3024:3024:1702.awebp??height=952&width=1610\"></p>\n<p>在拿到了 GPU Buffer 之后，就可以与算法愉快的进行相关的识别了，并且使用硬解抽帧之后对于 CPU 的使用率降到了15%左右。</p>\n<img src=\"https://cdn.julis.wang/blog/img/e05acc59ef49439e98293d38695991c2.png\">\n\n<h2 id=\"三、总结\"><a href=\"#三、总结\" class=\"headerlink\" title=\"三、总结\"></a>三、总结</h2><p>使用 MediaCodec 抽帧最大的优点就是能够使用硬件进行解码，降低 CPU 的使用率，并且整个帧数据可以存在于 GPU 上，算法侧也能直接拿取数据进行进行识别，能比较好的提升 “抽帧-识别” 的效率。但由于硬解码在不同的硬件上表现的性能有一定的差异，以及在不同的视频与FFmpeg上也有存在不同的性能差异，各有优劣，所以在后续的方案上，针对于不同的视频可能会采取不同的方案进行抽帧。</p>\n<p>参考：</p>\n<p>1.<a href=\"https://bigflake.com/mediacodec/ExtractMpegFramesTest_egl14.java.txt\">ExtractMpegFramesTest.java</a></p>\n<p>2.<a href=\"https://source.android.google.cn/devices/graphics/arch-st?hl=zh-c\">SurfaceTexture</a></p>\n<p>3.<a href=\"https://juejin.cn/post/701251727476817923\">Android Opengl OES 纹理渲染到 GL_TEXTURE_2D</a></p>\n","cover":null,"images":["https://cdn.julis.wang/blog/img/59036b70b7b44ccbad6b0b5c75445820.png","https://cdn.julis.wang/blog/img/b256cc7c59104dfa992e7672be571009.png","https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f9b96bb960304a46867fe7d65a27f540~tplv-k3u1fbpfcp-zoom-crop-mark:3024:3024:3024:1702.awebp??height=952&width=1610","https://cdn.julis.wang/blog/img/e05acc59ef49439e98293d38695991c2.png"],"content":"<p>要对移动端的抽帧，对于 iOS 来说，有 <a href=\"https://developer.apple.com/documentation/avfoundation\">AVFoundation</a> 这样一个神奇的库，开箱即用，已经支持了抽帧并且效率非常的高。而 Android 就不那么乐观了，Android 自带的 <code>MediaMetadataRetriever</code> 也能实现抽帧并将帧数据转化为 Bitmap，但效率非常低，平均抽取一帧需要 200ms-300ms，这当然满足不了我们的需求。无独有偶，Android 还提供了另一个类 <code>MediaCodec</code>-用于对音视频进行编解码的类，它通过访问底层的 codec 来实现编解码的功能，我们能对解码的数据进行定制化处理，本文也主要讲解利用 MediaCodec 进行抽帧。</p>\n<h2 id=\"一、MediaCodec\"><a href=\"#一、MediaCodec\" class=\"headerlink\" title=\"一、MediaCodec\"></a>一、MediaCodec</h2><p>为什么选择 MediaCodec? 项目的前期做了比较多的调研，在 Android 平台上除了 <code>MediaCodec</code> 还可以实现抽帧的方案有：<code>MediaMetadataRetriever</code>、<code>OpenCV</code>、<code>FFmpeg</code>，对于前两者实现效率非常的低，获取成本也比较大，对于 <code>FFmpeg</code>方案有进行了一定的尝试，ffmpeg是软解码抽帧(当然ffmpeg也可以 ffmpeg+mediaCodec 进行硬解码)，在设置 <code>AVCodecContext-&gt;thread_count=8</code> 速度提升了很多个档次，但对于 CPU 的使用率非常的高，消耗资源比较严重，不利于手机的流畅度，这里不再赘述。</p>\n<img src=\"https://cdn.julis.wang/blog/img/59036b70b7b44ccbad6b0b5c75445820.png\">\n\n<p>如上图所示 ffmpeg 软解 CPU 的使用率，维持在80%左右。</p>\n<p>MediaCodec 实现抽帧主要是参考 bigflake 网站提供的抽帧 Demo:<br><a href=\"https://bigflake.com/mediacodec/ExtractMpegFramesTest_egl14.java.txt\">ExtractMpegFramesTest</a></p>\n<p>主要方案流程如下图所示：</p>\n<img src=\"https://cdn.julis.wang/blog/img/b256cc7c59104dfa992e7672be571009.png\">\n<p>方案使用 <code>MediaExtractor</code> 获取 Codec-specific Data(对于H.264来说，”csd-0”和”csd-1”分别对应sps和pps；对于AAC来说，”csd-0”对应ADTS)发送给 <code>MediaCodec</code> 进行解码，将解码后的数据存放在 <code>Surface</code>，由于不需要将解码后的帧进行播放展示，我们进行离屏渲染(Pbuffer)，通过 <code>glReadPixels()</code> 将 GPU 渲染完存在显存数据，回传内存。获取到对应帧 Buffer 数据之后，再利用<code>Bitmap.copyPixelsFromBuffer</code> 创建 Android 平台 Bitmap 对象。</p>\n<p>但整个方案尝试下来之后发现：使用 <code>glReadPixels</code> 将显存数据回传，以及保存 Bitmap 是比较耗时以及消耗内存的操作。</p>\n<p>那么我们可以将数据不进行回传也不保存为 Bitmap，而直接使用 GPU 上的数据进行识别么？</p>\n<h2 id=\"二、GPU-Buffer-生成流程\"><a href=\"#二、GPU-Buffer-生成流程\" class=\"headerlink\" title=\"二、GPU Buffer 生成流程\"></a>二、GPU Buffer 生成流程</h2><p>在创建GPU Buffer之前我们需要简单介绍一下 <code>SurfaceTexture</code>，SurfaceTexture 是离屏渲染,内部包含了一个BufferQueue，可以把 Surface 生成的图像流，转换为纹理，供进一步加工使用。那么 <code>SurfaceTexture</code> 与前面的 MediaCodec 结合起来</p>\n<p>我们的目的是为了将 GPU 上的图片 buffer 传递给算法侧进行识别，来自 SurfaceTexture 只支持外部 GLES 纹理<code>GL_TEXTURE_EXTERNAL_OES</code>，而算法一般都是基于 <code>OpenGL</code>使用 <code>GL_TEXTURE_2D</code> , 所以需要客户端这边做一个转换工作。</p>\n<p>外部纹理 <code>GL_TEXTURE_EXTERNAL_OES</code> 的主要优势是它们能够直接从 BufferQueue 数据进行渲染。</p>\n<p>整体流程如下图所示：<br><img src=\"https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f9b96bb960304a46867fe7d65a27f540~tplv-k3u1fbpfcp-zoom-crop-mark:3024:3024:3024:1702.awebp??height=952&width=1610\"></p>\n<p>在拿到了 GPU Buffer 之后，就可以与算法愉快的进行相关的识别了，并且使用硬解抽帧之后对于 CPU 的使用率降到了15%左右。</p>\n<img src=\"https://cdn.julis.wang/blog/img/e05acc59ef49439e98293d38695991c2.png\">\n\n<h2 id=\"三、总结\"><a href=\"#三、总结\" class=\"headerlink\" title=\"三、总结\"></a>三、总结</h2><p>使用 MediaCodec 抽帧最大的优点就是能够使用硬件进行解码，降低 CPU 的使用率，并且整个帧数据可以存在于 GPU 上，算法侧也能直接拿取数据进行进行识别，能比较好的提升 “抽帧-识别” 的效率。但由于硬解码在不同的硬件上表现的性能有一定的差异，以及在不同的视频与FFmpeg上也有存在不同的性能差异，各有优劣，所以在后续的方案上，针对于不同的视频可能会采取不同的方案进行抽帧。</p>\n<p>参考：</p>\n<p>1.<a href=\"https://bigflake.com/mediacodec/ExtractMpegFramesTest_egl14.java.txt\">ExtractMpegFramesTest.java</a></p>\n<p>2.<a href=\"https://source.android.google.cn/devices/graphics/arch-st?hl=zh-c\">SurfaceTexture</a></p>\n<p>3.<a href=\"https://juejin.cn/post/701251727476817923\">Android Opengl OES 纹理渲染到 GL_TEXTURE_2D</a></p>\n","categories":[{"name":"技术文章","slug":"technology","api":"api/categories/technology.json"}],"tags":[{"name":"FFmpeg","slug":"FFmpeg","api":"api/tags/FFmpeg.json"},{"name":"MediaCodec","slug":"MediaCodec","api":"api/tags/MediaCodec.json"}],"api":"api/posts/2022/02/22/Android-视频抽帧相关.json"},{"title":"Android音视频-初识FFmpeg","slug":"音视频-初识FFmpeg","date":"2021-11-14T01:49:00.000Z","updated":"2025-05-20T11:46:57.000Z","comments":true,"url":"2021/11/14/音视频-初识FFmpeg/","excerpt":"<p>已经很久没有写过技术博客了，这段时间加入了新公司，主要时间花在熟悉新业务的技术上。而新的业务主要跟音视频相关，关于音视频的尝试在加入新公司之前，自己有做相关demo的尝试与学习，可以参看<a href=\"https://github.com/VomPom/JProject/tree/master/app/src/main/java/wang/julis/jproject/example/media\">音视频相关学习demo</a>。当然，那都是自己“想当然”学习的一些东西，虽然实际工作中并没有派上太大的用处，但让我对音视频相关的基础知识有了一定的概念，对后面的技术尝试做了铺垫。第一个技术挑战比较大的就是进行：<strong>视频抽帧</strong>，关于视频抽帧网上有很多很多文章进行讲解，但……我始终没有找到一个效率很高的解决方案。直到我遇见了 ffmpeg，仿佛打开了新世界的大门……</p>\n<h2 id=\"关于FFmpeg\"><a href=\"#关于FFmpeg\" class=\"headerlink\" title=\"关于FFmpeg\"></a>关于FFmpeg</h2><p>刚接触 ffmpeg 时，我一脸懵逼，完全不知道该怎么做，也不知道在哪里开始进行学习，后来在<a href=\"https://blog.csdn.net/leixiaohua1020\">雷霄骅大神的博客</a>中渐渐找到了感觉，膜拜！不过雷神的博客代码是基于老版本的 ffmpeg api，推荐搭配<a href=\"https://github.com/FFmpeg/FFmpeg/tree/master/doc/examples\">官方example</a>，先跑通雷声的博客，再对照官方的例子对进行api相关接口的修改。</p>\n<p>当然，想要使用 ffmpeg编写代码之前，我们首先要做的是对 FFmpeg 进行so库编译，这一步也是难倒了众多的英雄好汉，引用<a href=\"https://juejin.cn/post/6844904039524597773\">FFmpeg so库编译</a>作者的话：</p>\n<blockquote>\n<p>为什么FFmpeg让人觉得很难搞？<br>我想主要是因为迈出第一步就很困难，连so库都编译不出来，后面的都是扯淡了。</p>\n</blockquote>\n<p>参考<a href=\"https://juejin.cn/post/6844904039524597773\">FFmpeg so库编译</a>文章能成功地打包出 ffmpeg.so，接下来就是添加在项目中运行。</p>\n<h2 id=\"踏上-FFmpeg-音视频之路\"><a href=\"#踏上-FFmpeg-音视频之路\" class=\"headerlink\" title=\"踏上 FFmpeg 音视频之路\"></a>踏上 FFmpeg 音视频之路</h2><p>关于音视频等开发，无论是做特效渲染还是做视频播放，那么最重要也是最基本的步骤就是：<strong>音视频解码</strong></p>\n<p>众所周知的是视频是由一帧帧视频帧(图片)&#x2F;音频帧编码组合而成</p>\n<p>视频解码要做的就是解码出视频文件中的每一帧，我们以:<strong>将视频转化为一帧帧的图片</strong>作为例进行学习。</p>\n<h2 id=\"FFmpeg-提取视频每一帧图像\"><a href=\"#FFmpeg-提取视频每一帧图像\" class=\"headerlink\" title=\"FFmpeg 提取视频每一帧图像\"></a>FFmpeg 提取视频每一帧图像</h2><p>在学习之前，我们思考一个问题：抛开 ffmpeg，如果让你去设计一个提取的代码，n你会怎么设计？</p>\n<p>因为视频是以文件流的形式存在，我相信很多人一上来就能想到这样的结构：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span> (!EOF) &#123; <span class=\"comment\">//当文件流没有结束</span></span><br><span class=\"line\">    <span class=\"type\">Stream</span> <span class=\"variable\">stream</span> <span class=\"operator\">=</span> getStream(); <span class=\"comment\">//获取一定区域的stream</span></span><br><span class=\"line\">    <span class=\"type\">Frame</span> <span class=\"variable\">steam</span> <span class=\"operator\">=</span> getFrame(stream); <span class=\"comment\">//Stream转化为视频帧</span></span><br><span class=\"line\">    <span class=\"type\">Picture</span> <span class=\"variable\">picture</span> <span class=\"operator\">=</span> decodeFrame(steam); <span class=\"comment\">//将视频帧转化为 .jpeg等格式图片</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>的确是这样的，这里是给出一份ffmpeg提取视频帧图片的核心逻辑：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\">AVFrame frame = av_frame_alloc(); </span><br><span class=\"line\"><span class=\"keyword\">while</span> (<span class=\"literal\">true</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (av_read_frame(fmt_ctx, &amp;avpkt) &gt;= <span class=\"number\">0</span>) &#123; <span class=\"comment\">// Return the next frame of a stream.</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (avpkt.stream_index == video_stream_index) &#123; <span class=\"comment\">//标识该AVPacket所属的视频/音频流。</span></span><br><span class=\"line\">            avcodec_send_packet(codeCtx, &amp;avpkt); <span class=\"comment\">//Supply raw packet data as input to a decoder.</span></span><br><span class=\"line\">            <span class=\"keyword\">while</span> (avcodec_receive_frame(codeCtx, frame) == <span class=\"number\">0</span>) &#123; <span class=\"comment\">//Return decoded output data from a decoder.</span></span><br><span class=\"line\">                <span class=\"built_in\">snprintf</span>(buf, <span class=\"keyword\">sizeof</span>(buf), <span class=\"string\">&quot;%s/frame-%d.jpg&quot;</span>, out_filename, frame_count);</span><br><span class=\"line\">                saveJpg(frame, buf);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            frame_count++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        av_packet_unref(&amp;avpkt);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        LOGE(<span class=\"string\">&quot;//Exit&quot;</span>);</span><br><span class=\"line\">        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>上面的代码块就是 ffmpeg 进行视频解码最核心的逻辑了，主要的注释也贴在了代码上，完整代码请查看<a href=\"https://github.com/VomPom/FFmpegLearn/blob/main/app/src/main/cpp/func/video_to_jpeg.cpp\">video_to_jpeg.cpp</a>，查看完整的代码后，会感觉到很惊讶：为什么这么复杂？特别是前面的初始化操作。放心，ffmpeg就像一套组合拳，有固定不变的套路，写一次就足够了，了解了其中的流程，之后理解起来就会很容易了。</p>\n<p>上面的代码我们还可以做一些其他处理，比如只获取关键帧、查找指定时间戳位置的帧、视频按2s一帧进行抽取、视频不保存为jpeg文件转化为Java的bitmap？</p>\n<p>这些实现需求也都是基于上述核心模块进行修改：</p>\n<p>如果<strong>想只获取关键帧</strong>，可以利用<code>AVFrame</code>对象的属性<code>AVFrame-&gt;key_frame</code>进行判断。</p>\n<p><strong>查找指定时间戳位置的帧</strong>：利用 <code>av_seek_frame</code>查找到指定帧时间最近的关键帧，然后依次进行编码，直到<code>pts</code>与目标时间相近</p>\n<p><strong>视频按2s一帧进行抽取</strong>：简单的操作可以去获取视频fps，比如视频25fps，可以使用一个计数器判断<code>if(frame_count%25==0)</code>,这时候则是刚好1s。当然这样子性能不太好。如果需要追求性能，那么也可以利用<code>av_seek_frame</code>，查找目标时间附近，然后循环进行解码直到目标时间。</p>\n<p><strong>视频不保存为jpeg文件转化为Java的Bitmap</strong>：只需要对最终获取的 <code>AVFrame</code>做不一样的操作进行了，获取到对应的buffer，再利用jni调用构造 Java 的 bitmap 对象。</p>\n<p>可以做的还有很多……</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>提取视频图片这个功能只是 FFmpeg 强大功能的九牛一毛，需要探究的还有很多很多……</p>\n<p>如果能跑起来 FFmpeg 最简单的例子，已经迈出了很大一步了，但如果要理解其中的原理，还需要更多的基础知识，以及像<code>AVPacket</code>、<code>AVFrame</code>、 <code>AVCodec</code> ……每一个类的数据结构，以及实现都需要仔细研究。</p>\n<p>自己在网上找到的 FFmpeg 相关的教程，以及自己想要去实现的功能的资源太少，很多东西都需要自己去摸索。有时候我总在怀疑：<strong>为什么这么基础且很实用的功能没有现成的轮子？</strong> 这可能也是现在音视频相关开发的现状吧，成熟可用的轮子相对而言较少，以及相关技术的分享可能不太好做。既然没有，那就靠自己一点点积累吧。</p>\n<p>学习之路，任重而道远呐。</p>\n","cover":null,"images":[],"content":"<p>已经很久没有写过技术博客了，这段时间加入了新公司，主要时间花在熟悉新业务的技术上。而新的业务主要跟音视频相关，关于音视频的尝试在加入新公司之前，自己有做相关demo的尝试与学习，可以参看<a href=\"https://github.com/VomPom/JProject/tree/master/app/src/main/java/wang/julis/jproject/example/media\">音视频相关学习demo</a>。当然，那都是自己“想当然”学习的一些东西，虽然实际工作中并没有派上太大的用处，但让我对音视频相关的基础知识有了一定的概念，对后面的技术尝试做了铺垫。第一个技术挑战比较大的就是进行：<strong>视频抽帧</strong>，关于视频抽帧网上有很多很多文章进行讲解，但……我始终没有找到一个效率很高的解决方案。直到我遇见了 ffmpeg，仿佛打开了新世界的大门……</p>\n<h2 id=\"关于FFmpeg\"><a href=\"#关于FFmpeg\" class=\"headerlink\" title=\"关于FFmpeg\"></a>关于FFmpeg</h2><p>刚接触 ffmpeg 时，我一脸懵逼，完全不知道该怎么做，也不知道在哪里开始进行学习，后来在<a href=\"https://blog.csdn.net/leixiaohua1020\">雷霄骅大神的博客</a>中渐渐找到了感觉，膜拜！不过雷神的博客代码是基于老版本的 ffmpeg api，推荐搭配<a href=\"https://github.com/FFmpeg/FFmpeg/tree/master/doc/examples\">官方example</a>，先跑通雷声的博客，再对照官方的例子对进行api相关接口的修改。</p>\n<p>当然，想要使用 ffmpeg编写代码之前，我们首先要做的是对 FFmpeg 进行so库编译，这一步也是难倒了众多的英雄好汉，引用<a href=\"https://juejin.cn/post/6844904039524597773\">FFmpeg so库编译</a>作者的话：</p>\n<blockquote>\n<p>为什么FFmpeg让人觉得很难搞？<br>我想主要是因为迈出第一步就很困难，连so库都编译不出来，后面的都是扯淡了。</p>\n</blockquote>\n<p>参考<a href=\"https://juejin.cn/post/6844904039524597773\">FFmpeg so库编译</a>文章能成功地打包出 ffmpeg.so，接下来就是添加在项目中运行。</p>\n<h2 id=\"踏上-FFmpeg-音视频之路\"><a href=\"#踏上-FFmpeg-音视频之路\" class=\"headerlink\" title=\"踏上 FFmpeg 音视频之路\"></a>踏上 FFmpeg 音视频之路</h2><p>关于音视频等开发，无论是做特效渲染还是做视频播放，那么最重要也是最基本的步骤就是：<strong>音视频解码</strong></p>\n<p>众所周知的是视频是由一帧帧视频帧(图片)&#x2F;音频帧编码组合而成</p>\n<p>视频解码要做的就是解码出视频文件中的每一帧，我们以:<strong>将视频转化为一帧帧的图片</strong>作为例进行学习。</p>\n<h2 id=\"FFmpeg-提取视频每一帧图像\"><a href=\"#FFmpeg-提取视频每一帧图像\" class=\"headerlink\" title=\"FFmpeg 提取视频每一帧图像\"></a>FFmpeg 提取视频每一帧图像</h2><p>在学习之前，我们思考一个问题：抛开 ffmpeg，如果让你去设计一个提取的代码，n你会怎么设计？</p>\n<p>因为视频是以文件流的形式存在，我相信很多人一上来就能想到这样的结构：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span> (!EOF) &#123; <span class=\"comment\">//当文件流没有结束</span></span><br><span class=\"line\">    <span class=\"type\">Stream</span> <span class=\"variable\">stream</span> <span class=\"operator\">=</span> getStream(); <span class=\"comment\">//获取一定区域的stream</span></span><br><span class=\"line\">    <span class=\"type\">Frame</span> <span class=\"variable\">steam</span> <span class=\"operator\">=</span> getFrame(stream); <span class=\"comment\">//Stream转化为视频帧</span></span><br><span class=\"line\">    <span class=\"type\">Picture</span> <span class=\"variable\">picture</span> <span class=\"operator\">=</span> decodeFrame(steam); <span class=\"comment\">//将视频帧转化为 .jpeg等格式图片</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>的确是这样的，这里是给出一份ffmpeg提取视频帧图片的核心逻辑：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\">AVFrame frame = av_frame_alloc(); </span><br><span class=\"line\"><span class=\"keyword\">while</span> (<span class=\"literal\">true</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (av_read_frame(fmt_ctx, &amp;avpkt) &gt;= <span class=\"number\">0</span>) &#123; <span class=\"comment\">// Return the next frame of a stream.</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (avpkt.stream_index == video_stream_index) &#123; <span class=\"comment\">//标识该AVPacket所属的视频/音频流。</span></span><br><span class=\"line\">            avcodec_send_packet(codeCtx, &amp;avpkt); <span class=\"comment\">//Supply raw packet data as input to a decoder.</span></span><br><span class=\"line\">            <span class=\"keyword\">while</span> (avcodec_receive_frame(codeCtx, frame) == <span class=\"number\">0</span>) &#123; <span class=\"comment\">//Return decoded output data from a decoder.</span></span><br><span class=\"line\">                <span class=\"built_in\">snprintf</span>(buf, <span class=\"keyword\">sizeof</span>(buf), <span class=\"string\">&quot;%s/frame-%d.jpg&quot;</span>, out_filename, frame_count);</span><br><span class=\"line\">                saveJpg(frame, buf);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            frame_count++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        av_packet_unref(&amp;avpkt);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        LOGE(<span class=\"string\">&quot;//Exit&quot;</span>);</span><br><span class=\"line\">        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>上面的代码块就是 ffmpeg 进行视频解码最核心的逻辑了，主要的注释也贴在了代码上，完整代码请查看<a href=\"https://github.com/VomPom/FFmpegLearn/blob/main/app/src/main/cpp/func/video_to_jpeg.cpp\">video_to_jpeg.cpp</a>，查看完整的代码后，会感觉到很惊讶：为什么这么复杂？特别是前面的初始化操作。放心，ffmpeg就像一套组合拳，有固定不变的套路，写一次就足够了，了解了其中的流程，之后理解起来就会很容易了。</p>\n<p>上面的代码我们还可以做一些其他处理，比如只获取关键帧、查找指定时间戳位置的帧、视频按2s一帧进行抽取、视频不保存为jpeg文件转化为Java的bitmap？</p>\n<p>这些实现需求也都是基于上述核心模块进行修改：</p>\n<p>如果<strong>想只获取关键帧</strong>，可以利用<code>AVFrame</code>对象的属性<code>AVFrame-&gt;key_frame</code>进行判断。</p>\n<p><strong>查找指定时间戳位置的帧</strong>：利用 <code>av_seek_frame</code>查找到指定帧时间最近的关键帧，然后依次进行编码，直到<code>pts</code>与目标时间相近</p>\n<p><strong>视频按2s一帧进行抽取</strong>：简单的操作可以去获取视频fps，比如视频25fps，可以使用一个计数器判断<code>if(frame_count%25==0)</code>,这时候则是刚好1s。当然这样子性能不太好。如果需要追求性能，那么也可以利用<code>av_seek_frame</code>，查找目标时间附近，然后循环进行解码直到目标时间。</p>\n<p><strong>视频不保存为jpeg文件转化为Java的Bitmap</strong>：只需要对最终获取的 <code>AVFrame</code>做不一样的操作进行了，获取到对应的buffer，再利用jni调用构造 Java 的 bitmap 对象。</p>\n<p>可以做的还有很多……</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>提取视频图片这个功能只是 FFmpeg 强大功能的九牛一毛，需要探究的还有很多很多……</p>\n<p>如果能跑起来 FFmpeg 最简单的例子，已经迈出了很大一步了，但如果要理解其中的原理，还需要更多的基础知识，以及像<code>AVPacket</code>、<code>AVFrame</code>、 <code>AVCodec</code> ……每一个类的数据结构，以及实现都需要仔细研究。</p>\n<p>自己在网上找到的 FFmpeg 相关的教程，以及自己想要去实现的功能的资源太少，很多东西都需要自己去摸索。有时候我总在怀疑：<strong>为什么这么基础且很实用的功能没有现成的轮子？</strong> 这可能也是现在音视频相关开发的现状吧，成熟可用的轮子相对而言较少，以及相关技术的分享可能不太好做。既然没有，那就靠自己一点点积累吧。</p>\n<p>学习之路，任重而道远呐。</p>\n","categories":[{"name":"技术文章","slug":"technology","api":"api/categories/technology.json"}],"tags":[{"name":"FFmpeg","slug":"FFmpeg","api":"api/tags/FFmpeg.json"}],"api":"api/posts/2021/11/14/音视频-初识FFmpeg.json"}],"info":{"type":"tag","name":"FFmpeg","slug":"FFmpeg"}},"api":"api/tags/FFmpeg/page.1.json"}